{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introducing Squirrels Squirrels is a Python API framework for creating APIs that generate SQL queries & dataframes dynamically from query parameters. Get started by going through the Tutorial . Or check out the Overview page for understanding the framework. Why the name \"squirrels\"? \"Squirrels\" stands for \" S tructured QU ery I nterface with R ealtime R endering and E laborate L anguage S ynchronization\". The current \"languages\" include SQL and Python. It's also called \"squirrels\" for the following reasons: \"SQURL\" was also considered as a name for the framework, which is short for \"SQL URL\". This sounds like \"squirrel\" Following the theme of using animal names (plural form) for useful Python packages (like \"pandas\")","title":"Home"},{"location":"#introducing-squirrels","text":"Squirrels is a Python API framework for creating APIs that generate SQL queries & dataframes dynamically from query parameters. Get started by going through the Tutorial . Or check out the Overview page for understanding the framework.","title":"Introducing Squirrels"},{"location":"#why-the-name-squirrels","text":"\"Squirrels\" stands for \" S tructured QU ery I nterface with R ealtime R endering and E laborate L anguage S ynchronization\". The current \"languages\" include SQL and Python. It's also called \"squirrels\" for the following reasons: \"SQURL\" was also considered as a name for the framework, which is short for \"SQL URL\". This sounds like \"squirrel\" Following the theme of using animal names (plural form) for useful Python packages (like \"pandas\")","title":"Why the name \"squirrels\"?"},{"location":"overview/","text":"Overview The Squirrels Framework Squirrels is a dynamic and flexible framework designed to simplify and automate data analysis tasks for Business Intelligence and data analytics professionals, while easing the burden on data and machine learning engineers. It allows users to generate complex SQL queries dynamically, based on query parameters, and deliver tabular results. The framework is designed to answer evolving business questions and is particularly useful when the volume of data increases over time. With a primary focus on reusability and flexibility, Squirrels allows for query logic to be stored and shared across multiple applications, thus promoting efficient use of resources and time. The framework makes it possible to create REST APIs that perform calculations, offering parameter values via query parameters and delivering tabular results via the response body. Features Dynamic Queries with SQL Jinja or Python Squirrels utilizes Jinja as a templating language for rendering complex SQL queries. These queries are grouped into 'datasets', enabling the dynamic generation of queries based on business needs. Additionally, Squirrels supports Python to generate dynamic queries, providing a more flexible tool for handling NoSQL databases and for executing more complex transformations when needed.\" API Access to Datasets Applications can access these datasets and their associated parameters via well-defined API endpoints. Cascading Parameters The framework supports dynamic cascading parameters that adjust based on the selected values. These parameters can be specified within the dataset folder or fetched from database lookup tables. In-memory Caching After the first API call, the framework caches parameter objects in memory, enhancing the performance of subsequent calls. Context Variables Squirrels allows for the creation of \"context variables\" at runtime, based on selected parameters. These context variables, along with fixed project variables, can be used within templated SQL queries. Database and Final Views Templated SQL queries or Python scripts are rendered to run against one or more databases to generate \"database views\". These views are then combined to form the final result or \"final view\". For improved scalability, this operation is performed in the API server's memory. The results are cached based on query parameters for efficiency. Framework Workflow 0. Initialize Query When a GET request is made to the base resource path of a project, all available datasets within the project are returned. 1. Parameter Retrieval & Caching If a GET request is made to a specific dataset's parameters, all relevant parameter details for that dataset are fetched and cached. This could involve retrieving data from a parameters.py file in the project's dataset folder or from database lookup tables. Once these objects are cached in memory, subsequent API requests will not need to query the database for parameter details again. 2. Parameter Setting For each API request, a copy of the cached parameters is created, and parameter values are assigned from the query parameters. These copies allow for concurrent API requests without risking parameter selection overrides. 3. Generating Database Views Next, templated SQL queries or Python scripts are rendered to create \"database views\" by the dataset API. The queries can access Python variables for parameter objects, context variables, or project variables. 4. Running the Database Queries The generated queries are then run against the database, and the results are then fetched back to the API. 5. Running the Final View Query Finally, a \"final view\" is created in the API server's memory, which consolidates all the database views to generate the final result for the dataset. The final view is also cached based on the query parameters provided, such that repeated API requests do not require redundant work. 6. Sending back the results The results are then sent back to the client by the server in the form of a JSON file using the schema outlined here: Front End Response . Applications Squirrels' versatility makes it a handy tool for various data analytics scenarios, extending beyond just financial data. It can be used to create APIs for analyzing weather metrics by time period/location, demographics of population segments, or revenue/expenses for various business segments. In essence, Squirrels is a powerful framework that promotes flexible, reusable, and efficient data analysis and answers evolving business questions, ensuring that your BI and data analysis is always ahead of the curve. Here's an example diagram of how a Squirrels project might be set up to have multiple datasets querying from multiple databases:","title":"Overview"},{"location":"overview/#overview","text":"","title":"Overview"},{"location":"overview/#the-squirrels-framework","text":"Squirrels is a dynamic and flexible framework designed to simplify and automate data analysis tasks for Business Intelligence and data analytics professionals, while easing the burden on data and machine learning engineers. It allows users to generate complex SQL queries dynamically, based on query parameters, and deliver tabular results. The framework is designed to answer evolving business questions and is particularly useful when the volume of data increases over time. With a primary focus on reusability and flexibility, Squirrels allows for query logic to be stored and shared across multiple applications, thus promoting efficient use of resources and time. The framework makes it possible to create REST APIs that perform calculations, offering parameter values via query parameters and delivering tabular results via the response body.","title":"The Squirrels Framework"},{"location":"overview/#features","text":"","title":"Features"},{"location":"overview/#dynamic-queries-with-sql-jinja-or-python","text":"Squirrels utilizes Jinja as a templating language for rendering complex SQL queries. These queries are grouped into 'datasets', enabling the dynamic generation of queries based on business needs. Additionally, Squirrels supports Python to generate dynamic queries, providing a more flexible tool for handling NoSQL databases and for executing more complex transformations when needed.\"","title":"Dynamic Queries with SQL Jinja or Python"},{"location":"overview/#api-access-to-datasets","text":"Applications can access these datasets and their associated parameters via well-defined API endpoints.","title":"API Access to Datasets"},{"location":"overview/#cascading-parameters","text":"The framework supports dynamic cascading parameters that adjust based on the selected values. These parameters can be specified within the dataset folder or fetched from database lookup tables.","title":"Cascading Parameters"},{"location":"overview/#in-memory-caching","text":"After the first API call, the framework caches parameter objects in memory, enhancing the performance of subsequent calls.","title":"In-memory Caching"},{"location":"overview/#context-variables","text":"Squirrels allows for the creation of \"context variables\" at runtime, based on selected parameters. These context variables, along with fixed project variables, can be used within templated SQL queries.","title":"Context Variables"},{"location":"overview/#database-and-final-views","text":"Templated SQL queries or Python scripts are rendered to run against one or more databases to generate \"database views\". These views are then combined to form the final result or \"final view\". For improved scalability, this operation is performed in the API server's memory. The results are cached based on query parameters for efficiency.","title":"Database and Final Views"},{"location":"overview/#framework-workflow","text":"","title":"Framework Workflow"},{"location":"overview/#0-initialize-query","text":"When a GET request is made to the base resource path of a project, all available datasets within the project are returned.","title":"0. Initialize Query"},{"location":"overview/#1-parameter-retrieval-caching","text":"If a GET request is made to a specific dataset's parameters, all relevant parameter details for that dataset are fetched and cached. This could involve retrieving data from a parameters.py file in the project's dataset folder or from database lookup tables. Once these objects are cached in memory, subsequent API requests will not need to query the database for parameter details again.","title":"1. Parameter Retrieval &amp; Caching"},{"location":"overview/#2-parameter-setting","text":"For each API request, a copy of the cached parameters is created, and parameter values are assigned from the query parameters. These copies allow for concurrent API requests without risking parameter selection overrides.","title":"2. Parameter Setting"},{"location":"overview/#3-generating-database-views","text":"Next, templated SQL queries or Python scripts are rendered to create \"database views\" by the dataset API. The queries can access Python variables for parameter objects, context variables, or project variables.","title":"3. Generating Database Views"},{"location":"overview/#4-running-the-database-queries","text":"The generated queries are then run against the database, and the results are then fetched back to the API.","title":"4. Running the Database Queries"},{"location":"overview/#5-running-the-final-view-query","text":"Finally, a \"final view\" is created in the API server's memory, which consolidates all the database views to generate the final result for the dataset. The final view is also cached based on the query parameters provided, such that repeated API requests do not require redundant work.","title":"5. Running the Final View Query"},{"location":"overview/#6-sending-back-the-results","text":"The results are then sent back to the client by the server in the form of a JSON file using the schema outlined here: Front End Response .","title":"6. Sending back the results"},{"location":"overview/#applications","text":"Squirrels' versatility makes it a handy tool for various data analytics scenarios, extending beyond just financial data. It can be used to create APIs for analyzing weather metrics by time period/location, demographics of population segments, or revenue/expenses for various business segments. In essence, Squirrels is a powerful framework that promotes flexible, reusable, and efficient data analysis and answers evolving business questions, ensuring that your BI and data analysis is always ahead of the curve. Here's an example diagram of how a Squirrels project might be set up to have multiple datasets querying from multiple databases:","title":"Applications"},{"location":"cli/credentials/","text":"Credential Management CLIs There are three commands used to access and govern credentials: squirrels set-credential squirrels get-all-credentials squirrels delete-credential To set a credential, the user can use the squirrels set-credential <key> command to do so. This will prompt for the username and password for the connection you wish to use associated with the specified key . The key positional argument is the name of the connection to be specified in either the squirrels.yaml manifest file, or the connections.py file Alternatively, you can also use squirrels set-credential <key> [--values VALUES VALUES] . Replace the two VALUES in the above command after the --value flag with the username and the password. For example, if one would like to set the credentials named example then one would run the following: $ squirrels set-credential example --values username 12345678 On the other hand, squirrels get-all-credentials can be used to all the credentials saved, and squirrels delete-credential <key> can be used to a key previously defined by set-credential .","title":"credential management"},{"location":"cli/credentials/#credential-management-clis","text":"There are three commands used to access and govern credentials: squirrels set-credential squirrels get-all-credentials squirrels delete-credential To set a credential, the user can use the squirrels set-credential <key> command to do so. This will prompt for the username and password for the connection you wish to use associated with the specified key . The key positional argument is the name of the connection to be specified in either the squirrels.yaml manifest file, or the connections.py file Alternatively, you can also use squirrels set-credential <key> [--values VALUES VALUES] . Replace the two VALUES in the above command after the --value flag with the username and the password. For example, if one would like to set the credentials named example then one would run the following: $ squirrels set-credential example --values username 12345678 On the other hand, squirrels get-all-credentials can be used to all the credentials saved, and squirrels delete-credential <key> can be used to a key previously defined by set-credential .","title":"Credential Management CLIs"},{"location":"cli/init/","text":"The init CLI The squirrels init command is the initializer command for the squirrels framework, it is used to set up a new project or to reinitialize an existing one. When used, it will populate the current directory with a barebones version of the squirrels framework, depending on the user's preference. By default, the files created will not overwrite files that already exist. This behaviour can be changed by using the --overwrite option. After executing the command, the user would be able to specify which files should be initialized by answering the following prompts: [?] Include all core project files? (Y/n): [?] What's the file format for the database view?: > sql py [?] Do you want to add a 'connections.py' file? (y/N): [?] Do you want to add a 'context.py' file? (y/N): [?] Do you want to add a 'selections.cfg' file? (y/N): [?] What's the file format for the final view (if any)?: > none sql py [?] What sample sqlite database do you wish to use (if any)?: > none sample_database seattle_weather The first question answers whether all project files should be generated. If Y or y is specified, it will then ask the user whether the database_view1 file should be either python or sql. It will then create all the core files, which include: A sample parameters.py file in the datasets/sample_dataset folder A sample database_view1.sql.j2 or database_view1.py file in the datasets/sample_dataset folder A .gitignore file A requirements.txt file A sample squirrels.yaml file Additional prompts are also provided to inquire whether the following files are needed. File Description connections.py Used to specify keys to SQL database connections by providing a dictionary of strings to sqlalchemy Engines or Pools. This can be used in addition to, or in place of, the db_connections section of squirrels.yaml context.py At runtime, after parameter selections are applied, this file can be used to transform selected parameter options into any python variable selections.cfg Can be used with the \"squirrels test\" command to apply parameter selections to test the rendered SQL queries final_view.sql.j2 or final_view.py A \"final view\" file can be specified (as sql or python) to join all the database views into a single dataframe In the last question, the user can choose to include a sample sqlite database. Current options include the sample_database and seattle_weather databases. Further usage details can be found by running squirrels init -h which prints the text below. The user can also choose which files to add by providing additional command line options, avoiding the prompts above. This applies to all command line options below except for -h and --overwrite . usage: squirrels init [-h] [--overwrite] [--core] [--db-view {sql,py}] [--connections] [--context] [--selections-cfg] [--final-view {sql,py}] [--sample-db {sample_database,seattle_weather}] options: -h, --help show this help message and exit --overwrite Overwrite files that already exist --core Include all core files --db-view {sql,py} Create database view as sql (default) or python file if \"--core\" is specified --connections Include the connections.py file --context Include the context.py file --selections-cfg Include the selections.cfg file --final-view {sql,py} Include final view as sql or python file --sample-db {sample_database,seattle_weather} Sample sqlite database to include","title":"init"},{"location":"cli/init/#the-init-cli","text":"The squirrels init command is the initializer command for the squirrels framework, it is used to set up a new project or to reinitialize an existing one. When used, it will populate the current directory with a barebones version of the squirrels framework, depending on the user's preference. By default, the files created will not overwrite files that already exist. This behaviour can be changed by using the --overwrite option. After executing the command, the user would be able to specify which files should be initialized by answering the following prompts: [?] Include all core project files? (Y/n): [?] What's the file format for the database view?: > sql py [?] Do you want to add a 'connections.py' file? (y/N): [?] Do you want to add a 'context.py' file? (y/N): [?] Do you want to add a 'selections.cfg' file? (y/N): [?] What's the file format for the final view (if any)?: > none sql py [?] What sample sqlite database do you wish to use (if any)?: > none sample_database seattle_weather The first question answers whether all project files should be generated. If Y or y is specified, it will then ask the user whether the database_view1 file should be either python or sql. It will then create all the core files, which include: A sample parameters.py file in the datasets/sample_dataset folder A sample database_view1.sql.j2 or database_view1.py file in the datasets/sample_dataset folder A .gitignore file A requirements.txt file A sample squirrels.yaml file Additional prompts are also provided to inquire whether the following files are needed. File Description connections.py Used to specify keys to SQL database connections by providing a dictionary of strings to sqlalchemy Engines or Pools. This can be used in addition to, or in place of, the db_connections section of squirrels.yaml context.py At runtime, after parameter selections are applied, this file can be used to transform selected parameter options into any python variable selections.cfg Can be used with the \"squirrels test\" command to apply parameter selections to test the rendered SQL queries final_view.sql.j2 or final_view.py A \"final view\" file can be specified (as sql or python) to join all the database views into a single dataframe In the last question, the user can choose to include a sample sqlite database. Current options include the sample_database and seattle_weather databases. Further usage details can be found by running squirrels init -h which prints the text below. The user can also choose which files to add by providing additional command line options, avoiding the prompts above. This applies to all command line options below except for -h and --overwrite . usage: squirrels init [-h] [--overwrite] [--core] [--db-view {sql,py}] [--connections] [--context] [--selections-cfg] [--final-view {sql,py}] [--sample-db {sample_database,seattle_weather}] options: -h, --help show this help message and exit --overwrite Overwrite files that already exist --core Include all core files --db-view {sql,py} Create database view as sql (default) or python file if \"--core\" is specified --connections Include the connections.py file --context Include the context.py file --selections-cfg Include the selections.cfg file --final-view {sql,py} Include final view as sql or python file --sample-db {sample_database,seattle_weather} Sample sqlite database to include","title":"The init CLI"},{"location":"cli/load-modules/","text":"The load-modules CLI The squirrels load-modules command loads all the modules specified in the modules section of squirrels.yaml . Each module can be specified as a git repository in the format git_url@tag or name=git_url@tag for a different repo name than the default name. For instance, suppose we have the following in the squirrels.yaml file. modules: - https://github.com/user/repo1.git@v1.0 - second_repo=https://github.com/user/repo2.git@v2.0 Running squirrels load-modules in the project directory will create a new modules folder with subdirectories repo1 and second_repo . Inside repo1 is the contents of the https://github.com/user/repo1.git repo at the v1.0 tag, and inside second_repo is the contents of the https://github.com/user/repo2.git repo at the v2.0 tag. Then, in any python file, you can use the new modules by a simple import (for instance, from modules.repo1 import ... ). Note that the modules folder is intentionally included in the .gitignore file.","title":"load-modules"},{"location":"cli/load-modules/#the-load-modules-cli","text":"The squirrels load-modules command loads all the modules specified in the modules section of squirrels.yaml . Each module can be specified as a git repository in the format git_url@tag or name=git_url@tag for a different repo name than the default name. For instance, suppose we have the following in the squirrels.yaml file. modules: - https://github.com/user/repo1.git@v1.0 - second_repo=https://github.com/user/repo2.git@v2.0 Running squirrels load-modules in the project directory will create a new modules folder with subdirectories repo1 and second_repo . Inside repo1 is the contents of the https://github.com/user/repo1.git repo at the v1.0 tag, and inside second_repo is the contents of the https://github.com/user/repo2.git repo at the v2.0 tag. Then, in any python file, you can use the new modules by a simple import (for instance, from modules.repo1 import ... ). Note that the modules folder is intentionally included in the .gitignore file.","title":"The load-modules CLI"},{"location":"cli/run/","text":"The run CLI The squirrels run command is the main command that actually activates the APIs for each of the datasets, including their parameters and results. When run locally, those will be hosted on the specified host and port. The run command provides the following options (this can be found from squirrels run -h ): usage: squirrels run [-h] [--no-cache] [--debug] [--host HOST] [--port PORT] options: -h, --help show this help message and exit --no-cache Do not cache any api results --debug In debug mode, all \"hidden parameters\" show in the parameters response --host HOST --port PORT The default host is 127.0.0.1 and the default port is 8000 . While running, you can be access http://127.0.0.1:8000 or http://localhost:8000 from the browser to interact with the squirrels UI. Assume you have a sample product named \"sample_product\", a sample dataset named \"sample_dataset\", and the major version is set to 1. You can append the following paths to http://localhost:8000 to retrieve various JSON results: URL Path Description /squirrels0 The catalog API /squirrels0/sample_product/v1/sample_dataset/parameters The parameters API /squirrels0/sample_product/v1/sample_dataset The dataset API You can press Ctrl + C to shut down the API server.","title":"run"},{"location":"cli/run/#the-run-cli","text":"The squirrels run command is the main command that actually activates the APIs for each of the datasets, including their parameters and results. When run locally, those will be hosted on the specified host and port. The run command provides the following options (this can be found from squirrels run -h ): usage: squirrels run [-h] [--no-cache] [--debug] [--host HOST] [--port PORT] options: -h, --help show this help message and exit --no-cache Do not cache any api results --debug In debug mode, all \"hidden parameters\" show in the parameters response --host HOST --port PORT The default host is 127.0.0.1 and the default port is 8000 . While running, you can be access http://127.0.0.1:8000 or http://localhost:8000 from the browser to interact with the squirrels UI. Assume you have a sample product named \"sample_product\", a sample dataset named \"sample_dataset\", and the major version is set to 1. You can append the following paths to http://localhost:8000 to retrieve various JSON results: URL Path Description /squirrels0 The catalog API /squirrels0/sample_product/v1/sample_dataset/parameters The parameters API /squirrels0/sample_product/v1/sample_dataset The dataset API You can press Ctrl + C to shut down the API server.","title":"The run CLI"},{"location":"cli/test/","text":"The test CLI The squirrels test <dataset> command is used to facilitate the debugging process for the user. For a given dataset, the test command creates outputs for parameters API response and rendered sql queries. The test command takes in a mandatory dataset argument, where the user can spcify the name of the dataset to be tested, as provided in squirrels.yaml file. When executed, the command will also create an outputs folder, where all the results will be stored. All the details on command line arguments be found using squirrels test -h . The result is as follows: usage: squirrels test [-h] [-c CFG] [-d DATA] [-r] dataset positional arguments: dataset Name of dataset (provided in squirrels.yaml) to test. Results are written in an \"outputs\" folder options: -h, --help show this help message and exit -c CFG, --cfg CFG Configuration file for parameter selections. Path is relative to the dataset's folder -d DATA, --data DATA Excel file with lookup data to avoid making a database connection. Path is relative to the dataset's folder -r, --runquery Runs all database queries and final view, and produce the results as csv files Using a selections.cfg File It is good practice to create a selections.cfg file for your datasets to use with the test command. You can create a sample selections.cfg file by running squirrels init --selections-cfg . The selections.cfg file should specify all the parameter names and selected values under the [parameters] header. The parameter names (left of equal signs) should be specified in the same order specified in parameters.py (which avoids ambiguity especially if parameter dependencies are set). The selected values (right of equal signs) should follow the same format that the front-end uses to specify selected values for various parameter types, described here . Assuming that the selections.cfg file is created in a dataset folder called example , simply run squirrels test example --cfg selections.cfg to render the SQL queries with the specified parameter selections. Using an Excel Workbook for DataSource Parameter Data In the absence of an internet connection, the test command would not work if there are datasource parameters linked to a dimension table/query from an external database. Thus, it is also a good practice to use an Excel workbook to contain all the dimension table data (or a sample of it). In the Excel workbook, the sheet name must be the name of the datasource parameter, and the residing table (starting at cell A1) must have the same columns as the linked dimension table/query. For example, suppose there is a DataSourceParameter defined like this: example_options = sr.SelectionDataSource('SELECT x as index, y as label FROM table', 'index', 'label') ds_param = sr.DataSourceParameter(sr.MultiSelectParameter, 'test_param', 'Test Parameter', example_options) Then the Excel workbook must have at least a worksheet named \"test_param\" containing a table with columns \"index\" and \"label\". Assuming the Excel workbook is named lu_data.xlsx in a dataset folder called example , simply run squirrels test example --data lu_data.xlsx to render the SQL queries without having to use an internet connection!","title":"test"},{"location":"cli/test/#the-test-cli","text":"The squirrels test <dataset> command is used to facilitate the debugging process for the user. For a given dataset, the test command creates outputs for parameters API response and rendered sql queries. The test command takes in a mandatory dataset argument, where the user can spcify the name of the dataset to be tested, as provided in squirrels.yaml file. When executed, the command will also create an outputs folder, where all the results will be stored. All the details on command line arguments be found using squirrels test -h . The result is as follows: usage: squirrels test [-h] [-c CFG] [-d DATA] [-r] dataset positional arguments: dataset Name of dataset (provided in squirrels.yaml) to test. Results are written in an \"outputs\" folder options: -h, --help show this help message and exit -c CFG, --cfg CFG Configuration file for parameter selections. Path is relative to the dataset's folder -d DATA, --data DATA Excel file with lookup data to avoid making a database connection. Path is relative to the dataset's folder -r, --runquery Runs all database queries and final view, and produce the results as csv files","title":"The test CLI"},{"location":"cli/test/#using-a-selectionscfg-file","text":"It is good practice to create a selections.cfg file for your datasets to use with the test command. You can create a sample selections.cfg file by running squirrels init --selections-cfg . The selections.cfg file should specify all the parameter names and selected values under the [parameters] header. The parameter names (left of equal signs) should be specified in the same order specified in parameters.py (which avoids ambiguity especially if parameter dependencies are set). The selected values (right of equal signs) should follow the same format that the front-end uses to specify selected values for various parameter types, described here . Assuming that the selections.cfg file is created in a dataset folder called example , simply run squirrels test example --cfg selections.cfg to render the SQL queries with the specified parameter selections.","title":"Using a selections.cfg File"},{"location":"cli/test/#using-an-excel-workbook-for-datasource-parameter-data","text":"In the absence of an internet connection, the test command would not work if there are datasource parameters linked to a dimension table/query from an external database. Thus, it is also a good practice to use an Excel workbook to contain all the dimension table data (or a sample of it). In the Excel workbook, the sheet name must be the name of the datasource parameter, and the residing table (starting at cell A1) must have the same columns as the linked dimension table/query. For example, suppose there is a DataSourceParameter defined like this: example_options = sr.SelectionDataSource('SELECT x as index, y as label FROM table', 'index', 'label') ds_param = sr.DataSourceParameter(sr.MultiSelectParameter, 'test_param', 'Test Parameter', example_options) Then the Excel workbook must have at least a worksheet named \"test_param\" containing a table with columns \"index\" and \"label\". Assuming the Excel workbook is named lu_data.xlsx in a dataset folder called example , simply run squirrels test example --data lu_data.xlsx to render the SQL queries without having to use an internet connection!","title":"Using an Excel Workbook for DataSource Parameter Data"},{"location":"front-end/best-practices/","text":"Best Practices for Using REST API Response Here are some best practices around using the response of the parameters and dataset API. If choosing to cache the response, the cache key should incorporate all query parameters, the \"x-minor-version\" header, and the \"x-num-decimals\" header. And coordinate with the data team to understand how frequently the back-end data changes to decide on an appropriate time-to-live for the cache. However, note that there is some level of caching done by the squirrels project already. Sometimes, the set of dataset columns can be different based on query parameters provided. If you are uploading the results to a database table with a fixed schema, then columns in the database table and not the dataset API response should be null. Also, columns in the dataset API response but not the database table should be ignored. The standard for new minor version of the dataset API should be that no existing columns are removed (though this is not the standard for new major versions). However, the ordering of the columns is not guaranteed. Thus when processing the result, use columns by name and not by its order.","title":"Best Practices for Using REST API Response"},{"location":"front-end/best-practices/#best-practices-for-using-rest-api-response","text":"Here are some best practices around using the response of the parameters and dataset API. If choosing to cache the response, the cache key should incorporate all query parameters, the \"x-minor-version\" header, and the \"x-num-decimals\" header. And coordinate with the data team to understand how frequently the back-end data changes to decide on an appropriate time-to-live for the cache. However, note that there is some level of caching done by the squirrels project already. Sometimes, the set of dataset columns can be different based on query parameters provided. If you are uploading the results to a database table with a fixed schema, then columns in the database table and not the dataset API response should be null. Also, columns in the dataset API response but not the database table should be ignored. The standard for new minor version of the dataset API should be that no existing columns are removed (though this is not the standard for new major versions). However, the ordering of the columns is not guaranteed. Thus when processing the result, use columns by name and not by its order.","title":"Best Practices for Using REST API Response"},{"location":"front-end/response/","text":"Response Schema The squirrels framework interacts with the front end by sending three types of JSON response: catalog parameters datasets Catalog The catalog response is named squirrels0, and its API path is: catalog: /squirrels0 , and includes the higher level information regarding the entire project, ie. major and minor version numbers, pahts to the datasets and parameters, etc. Its JSON schema is as follows: { \"$schema\": \"https://json-schema.org/draft/2020-12/schema\", \"type\": \"object\", \"properties\": { \"response_version\": { \"type\": \"integer\", \"description\": \"Version of response to control the logic for parsing\" }, \"products\": { \"type\": \"array\", \"description\": \"The list of API products in the catalog\", \"items\": { \"type\": \"object\", \"properties\": { \"name\": { \"type\": \"string\", \"description\": \"Name of the product (may contain '/') specified in API path\" }, \"versions\": { \"type\": \"array\", \"description\": \"List of major versions for the product and applicable datasets\", \"items\": { \"type\": \"object\", \"properties\": { \"major_version\": { \"type\": \"integer\", \"description\": \"Major version number for product, which is also specified in API path\" }, \"datasets\": { \"type\": \"array\", \"description\": \"List of datasets applicable to major version\", \"items\": { \"type\": \"object\", \"properties\": { \"name\": { \"type\": \"string\", \"description\": \"Name of dataset specified in API path\" }, \"label\": { \"type\": \"string\", \"description\": \"Display label dataset\" }, \"parameters_path\": { \"type\": \"string\", \"description\": \"API path to dataset parameters. In the form '/<product>/v<major version>/<dataset>/parameters\" }, \"result_path\": { \"type\": \"string\", \"description\": \"API path to dataset results. In the form '/<product>/v<major version>/<dataset>\" }, \"first_minor_version\": { \"type\": \"integer\", \"description\": \"The first minor version (in current major version) where the dataset was included. Datasets can only be removed in a new major version\" } }, \"required\": [ \"name\", \"label\", \"parameters_path\", \"result_path\", \"first_minor_version\" ] } } }, \"required\": [ \"major_version\", \"datasets\" ] } } }, \"required\": [ \"name\", \"versions\" ] } } }, \"required\": [ \"response_version\", \"products\" ] } Below is an example response from the weather example: { \"response_version\": 0, \"products\": [ { \"name\": \"seattle_weather\", \"versions\": [ { \"major_version\": 1, \"latest_minor_version\": 0, \"datasets\": [ { \"name\": \"weather_by_time\", \"label\": \"Weather by Time of Year\", \"parameters_path\": \"/squirrels0/seattle-weather/v1/weather-by-time/parameters\", \"result_path\": \"/squirrels0/seattle-weather/v1/weather-by-time\", \"first_minor_version\": 0 }, { \"name\": \"weather_trend\", \"label\": \"Weather Trend\", \"parameters_path\": \"/squirrels0/seattle-weather/v1/weather-trend/parameters\", \"result_path\": \"/squirrels0/seattle-weather/v1/weather-trend\", \"first_minor_version\": 0 } ] } ] } ] } Parameters The parameters response provides the information regarding what parmeters is to be shown, and is named parameters Its API path is as follows: /squirrels0/<product>/v<major version>/<dataset>/parameters Below is the JSON schema: { \"$schema\": \"https://json-schema.org/draft/2020-12/schema\", \"type\": \"object\", \"properties\": { \"response_version\": { \"type\": \"integer\", \"description\": \"Version of response to control the logic for parsing\" }, \"parameters\": { \"type\": \"array\", \"description\": \"List of parameters application for the dataset\", \"items\": { \"type\": \"object\", \"properties\": { \"widget_type\": { \"type\": \"string\", \"description\": \"Type of the parameter (SingleSelectParameter, MultiSelectParameter, DateParameter, NumberParameter, etc.)\" }, \"name\": { \"type\": \"string\", \"description\": \"Name of the parameter, matches the query parameter name for the dataset API\" }, \"label\": { \"type\": \"string\", \"description\": \"Display label for the parameter\" }, \"options\": { \"type\": \"array\", \"description\": \"List of selection options for SingleSelectParameter and MultiSelectParameter\", \"items\": { \"type\": \"object\", \"properties\": { \"id\": { \"type\": \"string\", \"description\": \"ID for the option, to be used to pass selected options in query parameters\" }, \"label\": { \"type\": \"string\", \"description\": \"Display label for the selection option\" } }, \"required\": [ \"id\", \"label\" ] } }, \"trigger_refresh\": { \"type\": \"boolean\", \"description\": \"Whether new parameter selections should trigger another parameters API call, which can be used to change the options of children parameters. Only applicable to (and required for) SingleSelectParameter and MultiSelectParameter\" }, \"selected_id\": { \"type\": \"string\", \"description\": \"ID of the selected option. Only applicable to (and required for) SingleSelectParameter\" }, \"selected_ids\": { \"type\": \"array\", \"description\": \"ID of the selected option(s). Only applicable to (and required for) MultiSelectParameter\", \"items\": { \"type\": \"string\" } }, \"include_all\": { \"type\": \"boolean\", \"description\": \"Flag for whether no selections is same as all selected. Only applicable to (and required for) MultiSelectParameter\" }, \"order_matters\": { \"type\": \"boolean\", \"description\": \"Flag for whether the order of the selection matters. Only applicable to (and required for) MultiSelectParameter\" }, \"selected_date\": { \"type\": \"string\", \"description\": \"Selected date in yyyy-mm-dd format. Only applicable to (and required for) DateParameter\" }, \"min_value\": { \"type\": \"string\", \"pattern\": \"/^\\d*\\.?\\d*$/\", \"description\": \"Minimum number for a number slider. Only applicable to (and required for) NumberParameter\" }, \"max_value\": { \"type\": \"string\", \"pattern\": \"/^\\d*\\.?\\d*$/\", \"description\": \"Maximum number for a number slider. Only applicable to (and required for) NumberParameter\" }, \"increment\": { \"type\": \"string\", \"pattern\": \"/^\\d*\\.?\\d*$/\", \"description\": \"Steps / intervals for a number slider. Only applicable to (and required for) NumberParameter\" }, \"selected_value\": { \"type\": \"string\", \"pattern\": \"/^\\d*\\.?\\d*$/\", \"description\": \"Selected number on a number slider. Only applicable to (and required for) NumberParameter\" } }, \"required\": [ \"widget_type\", \"name\", \"label\" ] } } }, \"required\": [ \"response_version\", \"parameters\" ] } Here's an example response from the weathers example: { \"response_version\": 0, \"parameters\": [ { \"widget_type\": \"SingleSelectParameter\", \"name\": \"group_by\", \"label\": \"Group By\", \"options\": [ { \"id\": \"0\", \"label\": \"Year\" }, { \"id\": \"1\", \"label\": \"Quarter\" }, { \"id\": \"2\", \"label\": \"Month\" }, { \"id\": \"3\", \"label\": \"Day of Year\" }, { \"id\": \"4\", \"label\": \"Condition\" } ], \"trigger_refresh\": false, \"selected_id\": \"0\" } ] } Dataset After the parameters have been selected, the dataset reponse is used to send over the actual data to be displayed/used in the form of a json file. Its API path is: dataset: /squirrels0/<product>/v<major version>/<dataset> and has the same name as the dataset. Below is its JSON schema: { \"$schema\": \"https://json-schema.org/draft/2020-12/schema\", \"type\": \"object\", \"properties\": { \"response_version\": { \"type\": \"integer\", \"description\": \"Version of response to control the logic for parsing\" }, \"schema\": { \"type\": \"object\", \"properties\": { \"fields\": { \"type\": \"array\", \"description\": \"The ordering of the columns and their data types\", \"items\": { \"type\": \"object\", \"properties\": { \"name\": { \"type\": \"string\", \"description\": \"Name of the column\" }, \"type\": { \"type\": \"string\", \"description\": \"Data type of the column (string, number, etc.)\" } }, \"required\": [ \"name\", \"type\" ] } }, \"dimensions\": { \"type\": \"array\", \"description\": \"The dimension columns in specific order\", \"items\": { \"type\": \"string\", \"description\": \"Name of the column\" } } }, \"required\": [ \"fields\", \"dimensions\" ] }, \"data\": { \"type\": \"array\", \"description\": \"List of rows represented as JSON objects\", \"items\": { \"type\": \"object\" } } }, \"required\": [ \"response_version\", \"schema\", \"data\" ] } Here's an example response from the weather example: { \"response_version\": 0, \"schema\": { \"fields\": [ { \"name\": \"year\", \"type\": \"integer\" }, { \"name\": \"temperature_high_C\", \"type\": \"number\" }, { \"name\": \"temperature_low_C\", \"type\": \"number\" }, { \"name\": \"precipitation_inches\", \"type\": \"number\" }, { \"name\": \"wind_mph\", \"type\": \"number\" } ], \"dimensions\": [] }, \"data\": [ { \"year\": 2012, \"temperature_high_C\": 15.2767759563, \"temperature_low_C\": 7.2896174863, \"precipitation_inches\": 3.349726776, \"wind_mph\": 3.4008196721 }, { \"year\": 2013, \"temperature_high_C\": 16.0589041096, \"temperature_low_C\": 8.1539726027, \"precipitation_inches\": 2.2684931507, \"wind_mph\": 3.015890411 }, { \"year\": 2014, \"temperature_high_C\": 16.995890411, \"temperature_low_C\": 8.6624657534, \"precipitation_inches\": 3.3775342466, \"wind_mph\": 3.3876712329 }, { \"year\": 2015, \"temperature_high_C\": 17.4279452055, \"temperature_low_C\": 8.8356164384, \"precipitation_inches\": 3.1210958904, \"wind_mph\": 3.1597260274 } ] }","title":"Response Schema"},{"location":"front-end/response/#response-schema","text":"The squirrels framework interacts with the front end by sending three types of JSON response: catalog parameters datasets","title":"Response Schema"},{"location":"front-end/response/#catalog","text":"The catalog response is named squirrels0, and its API path is: catalog: /squirrels0 , and includes the higher level information regarding the entire project, ie. major and minor version numbers, pahts to the datasets and parameters, etc. Its JSON schema is as follows: { \"$schema\": \"https://json-schema.org/draft/2020-12/schema\", \"type\": \"object\", \"properties\": { \"response_version\": { \"type\": \"integer\", \"description\": \"Version of response to control the logic for parsing\" }, \"products\": { \"type\": \"array\", \"description\": \"The list of API products in the catalog\", \"items\": { \"type\": \"object\", \"properties\": { \"name\": { \"type\": \"string\", \"description\": \"Name of the product (may contain '/') specified in API path\" }, \"versions\": { \"type\": \"array\", \"description\": \"List of major versions for the product and applicable datasets\", \"items\": { \"type\": \"object\", \"properties\": { \"major_version\": { \"type\": \"integer\", \"description\": \"Major version number for product, which is also specified in API path\" }, \"datasets\": { \"type\": \"array\", \"description\": \"List of datasets applicable to major version\", \"items\": { \"type\": \"object\", \"properties\": { \"name\": { \"type\": \"string\", \"description\": \"Name of dataset specified in API path\" }, \"label\": { \"type\": \"string\", \"description\": \"Display label dataset\" }, \"parameters_path\": { \"type\": \"string\", \"description\": \"API path to dataset parameters. In the form '/<product>/v<major version>/<dataset>/parameters\" }, \"result_path\": { \"type\": \"string\", \"description\": \"API path to dataset results. In the form '/<product>/v<major version>/<dataset>\" }, \"first_minor_version\": { \"type\": \"integer\", \"description\": \"The first minor version (in current major version) where the dataset was included. Datasets can only be removed in a new major version\" } }, \"required\": [ \"name\", \"label\", \"parameters_path\", \"result_path\", \"first_minor_version\" ] } } }, \"required\": [ \"major_version\", \"datasets\" ] } } }, \"required\": [ \"name\", \"versions\" ] } } }, \"required\": [ \"response_version\", \"products\" ] } Below is an example response from the weather example: { \"response_version\": 0, \"products\": [ { \"name\": \"seattle_weather\", \"versions\": [ { \"major_version\": 1, \"latest_minor_version\": 0, \"datasets\": [ { \"name\": \"weather_by_time\", \"label\": \"Weather by Time of Year\", \"parameters_path\": \"/squirrels0/seattle-weather/v1/weather-by-time/parameters\", \"result_path\": \"/squirrels0/seattle-weather/v1/weather-by-time\", \"first_minor_version\": 0 }, { \"name\": \"weather_trend\", \"label\": \"Weather Trend\", \"parameters_path\": \"/squirrels0/seattle-weather/v1/weather-trend/parameters\", \"result_path\": \"/squirrels0/seattle-weather/v1/weather-trend\", \"first_minor_version\": 0 } ] } ] } ] }","title":"Catalog"},{"location":"front-end/response/#parameters","text":"The parameters response provides the information regarding what parmeters is to be shown, and is named parameters Its API path is as follows: /squirrels0/<product>/v<major version>/<dataset>/parameters Below is the JSON schema: { \"$schema\": \"https://json-schema.org/draft/2020-12/schema\", \"type\": \"object\", \"properties\": { \"response_version\": { \"type\": \"integer\", \"description\": \"Version of response to control the logic for parsing\" }, \"parameters\": { \"type\": \"array\", \"description\": \"List of parameters application for the dataset\", \"items\": { \"type\": \"object\", \"properties\": { \"widget_type\": { \"type\": \"string\", \"description\": \"Type of the parameter (SingleSelectParameter, MultiSelectParameter, DateParameter, NumberParameter, etc.)\" }, \"name\": { \"type\": \"string\", \"description\": \"Name of the parameter, matches the query parameter name for the dataset API\" }, \"label\": { \"type\": \"string\", \"description\": \"Display label for the parameter\" }, \"options\": { \"type\": \"array\", \"description\": \"List of selection options for SingleSelectParameter and MultiSelectParameter\", \"items\": { \"type\": \"object\", \"properties\": { \"id\": { \"type\": \"string\", \"description\": \"ID for the option, to be used to pass selected options in query parameters\" }, \"label\": { \"type\": \"string\", \"description\": \"Display label for the selection option\" } }, \"required\": [ \"id\", \"label\" ] } }, \"trigger_refresh\": { \"type\": \"boolean\", \"description\": \"Whether new parameter selections should trigger another parameters API call, which can be used to change the options of children parameters. Only applicable to (and required for) SingleSelectParameter and MultiSelectParameter\" }, \"selected_id\": { \"type\": \"string\", \"description\": \"ID of the selected option. Only applicable to (and required for) SingleSelectParameter\" }, \"selected_ids\": { \"type\": \"array\", \"description\": \"ID of the selected option(s). Only applicable to (and required for) MultiSelectParameter\", \"items\": { \"type\": \"string\" } }, \"include_all\": { \"type\": \"boolean\", \"description\": \"Flag for whether no selections is same as all selected. Only applicable to (and required for) MultiSelectParameter\" }, \"order_matters\": { \"type\": \"boolean\", \"description\": \"Flag for whether the order of the selection matters. Only applicable to (and required for) MultiSelectParameter\" }, \"selected_date\": { \"type\": \"string\", \"description\": \"Selected date in yyyy-mm-dd format. Only applicable to (and required for) DateParameter\" }, \"min_value\": { \"type\": \"string\", \"pattern\": \"/^\\d*\\.?\\d*$/\", \"description\": \"Minimum number for a number slider. Only applicable to (and required for) NumberParameter\" }, \"max_value\": { \"type\": \"string\", \"pattern\": \"/^\\d*\\.?\\d*$/\", \"description\": \"Maximum number for a number slider. Only applicable to (and required for) NumberParameter\" }, \"increment\": { \"type\": \"string\", \"pattern\": \"/^\\d*\\.?\\d*$/\", \"description\": \"Steps / intervals for a number slider. Only applicable to (and required for) NumberParameter\" }, \"selected_value\": { \"type\": \"string\", \"pattern\": \"/^\\d*\\.?\\d*$/\", \"description\": \"Selected number on a number slider. Only applicable to (and required for) NumberParameter\" } }, \"required\": [ \"widget_type\", \"name\", \"label\" ] } } }, \"required\": [ \"response_version\", \"parameters\" ] } Here's an example response from the weathers example: { \"response_version\": 0, \"parameters\": [ { \"widget_type\": \"SingleSelectParameter\", \"name\": \"group_by\", \"label\": \"Group By\", \"options\": [ { \"id\": \"0\", \"label\": \"Year\" }, { \"id\": \"1\", \"label\": \"Quarter\" }, { \"id\": \"2\", \"label\": \"Month\" }, { \"id\": \"3\", \"label\": \"Day of Year\" }, { \"id\": \"4\", \"label\": \"Condition\" } ], \"trigger_refresh\": false, \"selected_id\": \"0\" } ] }","title":"Parameters"},{"location":"front-end/response/#dataset","text":"After the parameters have been selected, the dataset reponse is used to send over the actual data to be displayed/used in the form of a json file. Its API path is: dataset: /squirrels0/<product>/v<major version>/<dataset> and has the same name as the dataset. Below is its JSON schema: { \"$schema\": \"https://json-schema.org/draft/2020-12/schema\", \"type\": \"object\", \"properties\": { \"response_version\": { \"type\": \"integer\", \"description\": \"Version of response to control the logic for parsing\" }, \"schema\": { \"type\": \"object\", \"properties\": { \"fields\": { \"type\": \"array\", \"description\": \"The ordering of the columns and their data types\", \"items\": { \"type\": \"object\", \"properties\": { \"name\": { \"type\": \"string\", \"description\": \"Name of the column\" }, \"type\": { \"type\": \"string\", \"description\": \"Data type of the column (string, number, etc.)\" } }, \"required\": [ \"name\", \"type\" ] } }, \"dimensions\": { \"type\": \"array\", \"description\": \"The dimension columns in specific order\", \"items\": { \"type\": \"string\", \"description\": \"Name of the column\" } } }, \"required\": [ \"fields\", \"dimensions\" ] }, \"data\": { \"type\": \"array\", \"description\": \"List of rows represented as JSON objects\", \"items\": { \"type\": \"object\" } } }, \"required\": [ \"response_version\", \"schema\", \"data\" ] } Here's an example response from the weather example: { \"response_version\": 0, \"schema\": { \"fields\": [ { \"name\": \"year\", \"type\": \"integer\" }, { \"name\": \"temperature_high_C\", \"type\": \"number\" }, { \"name\": \"temperature_low_C\", \"type\": \"number\" }, { \"name\": \"precipitation_inches\", \"type\": \"number\" }, { \"name\": \"wind_mph\", \"type\": \"number\" } ], \"dimensions\": [] }, \"data\": [ { \"year\": 2012, \"temperature_high_C\": 15.2767759563, \"temperature_low_C\": 7.2896174863, \"precipitation_inches\": 3.349726776, \"wind_mph\": 3.4008196721 }, { \"year\": 2013, \"temperature_high_C\": 16.0589041096, \"temperature_low_C\": 8.1539726027, \"precipitation_inches\": 2.2684931507, \"wind_mph\": 3.015890411 }, { \"year\": 2014, \"temperature_high_C\": 16.995890411, \"temperature_low_C\": 8.6624657534, \"precipitation_inches\": 3.3775342466, \"wind_mph\": 3.3876712329 }, { \"year\": 2015, \"temperature_high_C\": 17.4279452055, \"temperature_low_C\": 8.8356164384, \"precipitation_inches\": 3.1210958904, \"wind_mph\": 3.1597260274 } ] }","title":"Dataset"},{"location":"front-end/selections/","text":"Passing Parameter Selections The method that the selected value(s) for a parameter is specified as a query parameter depends on the \"widget_type\" of the parameter. See table below for details: Widget Type Example Format Description SingleSelectParameter a0 The name of the selected value MultiSelectParameter [\"x0\",\"x2\"] The JSON list of the selected values DateParameter 2022-01-01 The selected date in the format 'yyyy-MM-dd' NumberParameter 6 The selected value as a number","title":"Passing Parameter Selections"},{"location":"front-end/selections/#passing-parameter-selections","text":"The method that the selected value(s) for a parameter is specified as a query parameter depends on the \"widget_type\" of the parameter. See table below for details: Widget Type Example Format Description SingleSelectParameter a0 The name of the selected value MultiSelectParameter [\"x0\",\"x2\"] The JSON list of the selected values DateParameter 2022-01-01 The selected date in the format 'yyyy-MM-dd' NumberParameter 6 The selected value as a number","title":"Passing Parameter Selections"},{"location":"how-to/common-vary/","text":"Design for Commonality and Variability Sharing common SQL syntax using Jinja import and macros In order to avoid duplications, the Jinja2 framework supports the use of macros to save a piece of SQL code template that can be used by other templates. To those unfamiliar with the term macro, a macro is essentially Jinja's analogy to a function. As we are using Jinja2 for our SQL templates, the squirrels framework supports the use of macros in all its SQL/Jinja files. To provide an example, let's say that you are analyzing the geographical distribution of different phone makers in the United States. For that purpose, you have three tables from different datasources that you've imported into your database, each with different schemas: tbl_android_users tbl_users_apple tbl_dumbphone_users All these tables have columns for user ID, location (city, county, state, etc), and phone ID, and you want a view with all the users, the state or the city (depending on the parameter), the type of phone they use, and a count of the number of phones that they have. For this example let's say that you have parameters.py defined in the following manner, where location is a single-select parameter that specifies the location with the following options City , County , and State . def main(args: Dict[str, Any], *p_args, **kwargs) -> Sequence[sr.Parameter]: location_options = [ sr.SelectParameterOption('0', 'City', column = 'CITY'), sr.SelectParameterOption('1', 'County', column = 'COUNTY'), sr.SelectParameterOption('2', 'State', column = 'STATE') ] location_param = sr.SingleSelectParameter('location', 'Location', location_options) return [location_param] If you were to write out the full query, you'd have something like this. SELECT ID_USER as USER_ID, {{ prms['location'].get_selected(\"column\") }}, 'Android' AS PHONE_TYPE, COUNT(DISTINCT PHONE_ID) AS CELL_COUNT FROM TBL_ANDROID_USERS GROUP BY USER_ID, {{ prms['location'].get_selected(\"column\") }} UNION ALL SELECT ID_ACCT as USER_ID, {{ prms['location'].get_selected(\"column\") }}, 'Apple' AS PHONE_TYPE, COUNT(DISTINCT PHONE_ID) AS CELL_COUNT FROM TBL_USERS_APPLE GROUP BY USER_ID, {{ prms['location'].get_selected(\"column\") }} UNION ALL SELECT ID_CUST as USER_ID, {{ prms['location'].get_selected(\"column\") }}, 'DumbPhone' AS PHONE_TYPE, COUNT(DISTINCT CELL_ID) AS CELL_COUNT FROM TBL_DUMBPHONE_USERS GROUP BY USER_ID, {{ prms['location'].get_selected(\"column\") }} Pretty repetitive, huh? Instead of writing out the entire thing, one way we can simplify this is to write a generic subquery in the form of a macro in a seperate file, which we'll name macros.sql.j2 . Inside this file, we will need to define a macro by writing: {% macro phone_macro(phone_table, user_id_column, phone_id_name, phone_type_name, location) -%} SELECT {{ user_id_column }} as USER_ID, {{ location }}, '{{ phone_type_name }}' AS PHONE_TYPE, COUNT(DISTINCT {{ phone_id_name }}) AS CELL_COUNT FROM {{ phone_table }} GROUP BY USER_ID, {{ location }} {%- endmacro -%} Here, a macro named phone_macro is defined, followed by the required variables. These variables can then be used by the definition of the macro with double curly brackets. The final {%- endmacro -%} commands specifies the end of the definition. Suppose the file is saved in the \"datasets\" folder. The macro can be imported into the main script by specifying the path of the script (relative to the project root), and the name of the macro. {% from 'datasets/macros.sql.j2' import phone_macro -%} The macro can then be called by using double curly braces, and passing in the variables in the following manner: {{ phone_macro('TBL_ANDROID_USERS', 'ID_USER', 'Android', 'PHONE_ID', prms['location'].get_selected(\"column\")) }} An alternative way to refer to the \"phone_macro\" can also be done as such: {% import 'datasets/macros.sql.j2' as m -%} {{ m.phone_macro('TBL_ANDROID_USERS', 'ID_USER', 'Android', 'PHONE_ID', prms['location'].get_selected(\"column\")) }} Rewriting the original script to use macros, we get something with much less duplicate code: {% from 'datasets/macros.sql.j2' import phone_macro -%} {% set location_col = prms['location'].get_selected(\"column\") -%} {{ phone_macro('TBL_ANDROID_USERS', 'ID_USER', 'Android', 'PHONE_ID', location_col) }} UNION ALL {{ phone_macro('TBL_USERS_APPLE', 'ID_ACCT', 'Apple', 'PHONE_ID', location_col) }} UNION ALL {{ phone_macro('TBL_DUMBPHONE_USERS', 'ID_CUST', 'DumbPhone', 'CELL_ID', location_col) }} Please note that this is only one possible use case, and that there are millions of other use cases. For some more possible use cases, this guide here provides some other use cases of macros used in sql Jinja templates. Although this is not squirrels specific, it should still serve as a nice reference. Sharing code with Python Similar to using Jinja and SQL, you can also import functions from other scripts using Python as well. To give an example, suppose that you have multiple different dataframes from different sources that you'd like to standardize by renaming the columns, and return joined table of all of them. If you were to do that all in the same script with the power of copy/pasting, you might have something like this: from typing import Dict, Any import pandas as pd import squirrels as sr def main(database_views: Dict[str, pd.DataFrame], prms: Dict[str, sr.Parameter], ctx: Dict[str, Any], args: Dict[str, Any], *p_args, **kwargs) -> pd.DataFrame: df1 = database_views['database_view1'].rename(columns={\"user_id\": \"id_user\", \"geo_id\": \"location\", \"account_id\": \"id_acct\"}) df1 = df1[[\"id_user\",\"location\",\"id_acct\"]] df2 = database_views['database_view2'].rename(columns={\"us_id\": \"id_user\", \"state\": \"location\", \"id_a\": \"id_acct\"}) df2 = df2[[\"id_user\",\"location\",\"id_acct\"]] df3 = database_views['database_view3'].rename(columns={\"cust_id\": \"id_user\", \"city\": \"location\", \"account_num\": \"id_acct\"}) df3 = df3[[\"id_user\",\"location\",\"id_acct\"]] return pd.concat([df1, df2, df3], ignore_index = True) (This is also a prime example of horrible style, please don't write code like this). In the seperate script, which we will name functions.py , we can create a function named standardize . import pandas as pd def standardize(df: pd.DataFrame, id_user_col: str, location_col: str, id_acct_col: str) -> pd.DataFrame: df = df.rename(columns={id_user_col: \"id_user\", location_col: \"location\", id_acct_col: \"id_acct\"}) return df[[\"id_user\",\"location\",\"id_acct\"]] Suppose functions.py is saved in the datasets folder. In the main script, we would then be able to import the file relative to the root of the project: from datasets import functions as f Rewriting the first example would result in something like the following: from typing import Dict, Any import pandas as pd import squirrels as sr from datasets import functions as f def main(database_views: Dict[str, pd.DataFrame], prms: Dict[str, sr.Parameter], ctx: Dict[str, Any], args: Dict[str, Any], *p_args, **kwargs) -> pd.DataFrame: df1 = f.standardize(database_views['database_view1']) df2 = f.standardize(database_views['database_view2']) df3 = f.standardize(database_views['database_view3']) return pd.concat([df1, df2, df3], ignore_index = True) Again, this is a pretty simple example, and importing scripts would allow for much more complex data manipulations to be organized and written in a much more readable manner.","title":"Design for Commonality and Variability"},{"location":"how-to/common-vary/#design-for-commonality-and-variability","text":"","title":"Design for Commonality and Variability"},{"location":"how-to/common-vary/#sharing-common-sql-syntax-using-jinja-import-and-macros","text":"In order to avoid duplications, the Jinja2 framework supports the use of macros to save a piece of SQL code template that can be used by other templates. To those unfamiliar with the term macro, a macro is essentially Jinja's analogy to a function. As we are using Jinja2 for our SQL templates, the squirrels framework supports the use of macros in all its SQL/Jinja files. To provide an example, let's say that you are analyzing the geographical distribution of different phone makers in the United States. For that purpose, you have three tables from different datasources that you've imported into your database, each with different schemas: tbl_android_users tbl_users_apple tbl_dumbphone_users All these tables have columns for user ID, location (city, county, state, etc), and phone ID, and you want a view with all the users, the state or the city (depending on the parameter), the type of phone they use, and a count of the number of phones that they have. For this example let's say that you have parameters.py defined in the following manner, where location is a single-select parameter that specifies the location with the following options City , County , and State . def main(args: Dict[str, Any], *p_args, **kwargs) -> Sequence[sr.Parameter]: location_options = [ sr.SelectParameterOption('0', 'City', column = 'CITY'), sr.SelectParameterOption('1', 'County', column = 'COUNTY'), sr.SelectParameterOption('2', 'State', column = 'STATE') ] location_param = sr.SingleSelectParameter('location', 'Location', location_options) return [location_param] If you were to write out the full query, you'd have something like this. SELECT ID_USER as USER_ID, {{ prms['location'].get_selected(\"column\") }}, 'Android' AS PHONE_TYPE, COUNT(DISTINCT PHONE_ID) AS CELL_COUNT FROM TBL_ANDROID_USERS GROUP BY USER_ID, {{ prms['location'].get_selected(\"column\") }} UNION ALL SELECT ID_ACCT as USER_ID, {{ prms['location'].get_selected(\"column\") }}, 'Apple' AS PHONE_TYPE, COUNT(DISTINCT PHONE_ID) AS CELL_COUNT FROM TBL_USERS_APPLE GROUP BY USER_ID, {{ prms['location'].get_selected(\"column\") }} UNION ALL SELECT ID_CUST as USER_ID, {{ prms['location'].get_selected(\"column\") }}, 'DumbPhone' AS PHONE_TYPE, COUNT(DISTINCT CELL_ID) AS CELL_COUNT FROM TBL_DUMBPHONE_USERS GROUP BY USER_ID, {{ prms['location'].get_selected(\"column\") }} Pretty repetitive, huh? Instead of writing out the entire thing, one way we can simplify this is to write a generic subquery in the form of a macro in a seperate file, which we'll name macros.sql.j2 . Inside this file, we will need to define a macro by writing: {% macro phone_macro(phone_table, user_id_column, phone_id_name, phone_type_name, location) -%} SELECT {{ user_id_column }} as USER_ID, {{ location }}, '{{ phone_type_name }}' AS PHONE_TYPE, COUNT(DISTINCT {{ phone_id_name }}) AS CELL_COUNT FROM {{ phone_table }} GROUP BY USER_ID, {{ location }} {%- endmacro -%} Here, a macro named phone_macro is defined, followed by the required variables. These variables can then be used by the definition of the macro with double curly brackets. The final {%- endmacro -%} commands specifies the end of the definition. Suppose the file is saved in the \"datasets\" folder. The macro can be imported into the main script by specifying the path of the script (relative to the project root), and the name of the macro. {% from 'datasets/macros.sql.j2' import phone_macro -%} The macro can then be called by using double curly braces, and passing in the variables in the following manner: {{ phone_macro('TBL_ANDROID_USERS', 'ID_USER', 'Android', 'PHONE_ID', prms['location'].get_selected(\"column\")) }} An alternative way to refer to the \"phone_macro\" can also be done as such: {% import 'datasets/macros.sql.j2' as m -%} {{ m.phone_macro('TBL_ANDROID_USERS', 'ID_USER', 'Android', 'PHONE_ID', prms['location'].get_selected(\"column\")) }} Rewriting the original script to use macros, we get something with much less duplicate code: {% from 'datasets/macros.sql.j2' import phone_macro -%} {% set location_col = prms['location'].get_selected(\"column\") -%} {{ phone_macro('TBL_ANDROID_USERS', 'ID_USER', 'Android', 'PHONE_ID', location_col) }} UNION ALL {{ phone_macro('TBL_USERS_APPLE', 'ID_ACCT', 'Apple', 'PHONE_ID', location_col) }} UNION ALL {{ phone_macro('TBL_DUMBPHONE_USERS', 'ID_CUST', 'DumbPhone', 'CELL_ID', location_col) }} Please note that this is only one possible use case, and that there are millions of other use cases. For some more possible use cases, this guide here provides some other use cases of macros used in sql Jinja templates. Although this is not squirrels specific, it should still serve as a nice reference.","title":"Sharing common SQL syntax using Jinja import and macros"},{"location":"how-to/common-vary/#sharing-code-with-python","text":"Similar to using Jinja and SQL, you can also import functions from other scripts using Python as well. To give an example, suppose that you have multiple different dataframes from different sources that you'd like to standardize by renaming the columns, and return joined table of all of them. If you were to do that all in the same script with the power of copy/pasting, you might have something like this: from typing import Dict, Any import pandas as pd import squirrels as sr def main(database_views: Dict[str, pd.DataFrame], prms: Dict[str, sr.Parameter], ctx: Dict[str, Any], args: Dict[str, Any], *p_args, **kwargs) -> pd.DataFrame: df1 = database_views['database_view1'].rename(columns={\"user_id\": \"id_user\", \"geo_id\": \"location\", \"account_id\": \"id_acct\"}) df1 = df1[[\"id_user\",\"location\",\"id_acct\"]] df2 = database_views['database_view2'].rename(columns={\"us_id\": \"id_user\", \"state\": \"location\", \"id_a\": \"id_acct\"}) df2 = df2[[\"id_user\",\"location\",\"id_acct\"]] df3 = database_views['database_view3'].rename(columns={\"cust_id\": \"id_user\", \"city\": \"location\", \"account_num\": \"id_acct\"}) df3 = df3[[\"id_user\",\"location\",\"id_acct\"]] return pd.concat([df1, df2, df3], ignore_index = True) (This is also a prime example of horrible style, please don't write code like this). In the seperate script, which we will name functions.py , we can create a function named standardize . import pandas as pd def standardize(df: pd.DataFrame, id_user_col: str, location_col: str, id_acct_col: str) -> pd.DataFrame: df = df.rename(columns={id_user_col: \"id_user\", location_col: \"location\", id_acct_col: \"id_acct\"}) return df[[\"id_user\",\"location\",\"id_acct\"]] Suppose functions.py is saved in the datasets folder. In the main script, we would then be able to import the file relative to the root of the project: from datasets import functions as f Rewriting the first example would result in something like the following: from typing import Dict, Any import pandas as pd import squirrels as sr from datasets import functions as f def main(database_views: Dict[str, pd.DataFrame], prms: Dict[str, sr.Parameter], ctx: Dict[str, Any], args: Dict[str, Any], *p_args, **kwargs) -> pd.DataFrame: df1 = f.standardize(database_views['database_view1']) df2 = f.standardize(database_views['database_view2']) df3 = f.standardize(database_views['database_view3']) return pd.concat([df1, df2, df3], ignore_index = True) Again, this is a pretty simple example, and importing scripts would allow for much more complex data manipulations to be organized and written in a much more readable manner.","title":"Sharing code with Python"},{"location":"how-to/custom-fields/","text":"Set Parameter Option Custom Fields When building out multi-select or single-select parameters, you can associate all parameter option with a custom attribute, and access the attribute for the selected parameter option(s) at runtime in context.py or the query views. Suppose you want to build a parameter for \"time period\" that has options \"Year to Date\" or \"Year over Year\", and you want to associate each option with one of squirrel's DateModifier classes. You would: Add the custom field \"date_modifier\" to each parameter option in parameters.py . Can be specified as arbitrary keyword arguments or using the custom_fields argument. Access the custom \"date_modifier\" at runtime for the selected option, and use it to transform some date string. More details on squirrel's date modifiers can be found in the how-to guide for Modify Dates Using Squirrel's dateutils . Custom fields can also come from lookup tables as \"custom columns\" when using the custom_cols argument in the constructor of SelectionDataSource for a DataSourceParameter . 1. Associating Custom Fields to Parameter Options In parameters.py , you can use arbitrary keyword arguments as follows to specify custom fields. Note the date_modifier keyword arguments to SelectParameterOption . from squirrels import dateutils as du import squirrels as sr ... ytd_date_modifier = du.DateStringModifier([du.DayIdxOfYear(1)]) yoy_date_modifier = du.DateStringModifier([du.OffsetYears(-1)]) time_period_options = [ sr.SelectParameterOption(\"t0\", \"Year to Date\", date_modifier=ytd_date_modifier), sr.SelectParameterOption(\"t1\", \"Year over Year\", date_modifier=yoy_date_modifier) ] time_period_param = sr.SingleSelectParameter(\"time_period\", \"Time Period\", time_period_options) You can also specify custom fields as a dictionary using the custom_fields argument. This is an alternative example for \"Year to Date\": sr.SelectParameterOption(\"t0\", \"Year to Date\", custom_fields={\"date_modifier\":ytd_date_modifier}) 2. Access the Custom Fields at Runtime You can get the date modifier(s) of the selected option(s) using the get_selected method for SingleSelectParameter (returns one value) or the get_selected_list method for MultiSelectParameter (returns a list of values). Both methods take a string argument called field (first positional argument) that lets you get the custom field(s) for the selected option(s). If the field is not specified, the methods return the SelectParameterOption object(s) instead. Assume we have a date string to modify called latest_date (perhaps derived from another parameter). The following example applies the selected date_modifier of the \"time_period\" parameter to latest_date , which can be done purely in Python in the context.py file. time_period_param: sr.SingleSelectParameter = prms[\"time_period\"] date_modifier = time_period_param.get_selected(\"date_modifier\") start_date = date_modifier.modify(latest_date) Alternatively, the selected date_modifier can also be accessed like this: date_modifier = time_period_param.get_selected().custom_fields[\"date_modifier\"] Note If you prefer to not use context.py , variables can be set in the Jinja SQL views with {% set var_name = ... %} . Specifying Custom Columns for DataSourceParameter Instead of using a date_modifier , suppose that the start date comes from a lookup table in the database instead. For instance, the lookup table can look like the following where the \"start_date_column\" gets updated regularly. time_period_id time_period_label start_date_column t0 Year to Date 2023-01-01 t1 Year over Year 2022-07-02 Instead of specifying a SingleSelectParameter for time_period_param , it can be a DataSourceParameter (using custom_cols ) that converts itself into a SingleSelectParameter instead. time_period_ds = sr.SelectionDataSource(\"time_period_table\", \"time_period_id\", \"time_period_label\", custom_cols={\"start_date\": \"start_date_column\"}) time_period_param = sr.DataSourceParameter(sr.SingleSelectParameter, \"time_period\", \"Time Period\", time_period_ds) Then, in context.py , the selected start date can be accessed as follows. time_period_param: sr.SingleSelectParameter = prms[\"time_period\"] start_date = time_period_param.get_selected(\"start_date\")","title":"Parameter Option Custom Fields"},{"location":"how-to/custom-fields/#set-parameter-option-custom-fields","text":"When building out multi-select or single-select parameters, you can associate all parameter option with a custom attribute, and access the attribute for the selected parameter option(s) at runtime in context.py or the query views. Suppose you want to build a parameter for \"time period\" that has options \"Year to Date\" or \"Year over Year\", and you want to associate each option with one of squirrel's DateModifier classes. You would: Add the custom field \"date_modifier\" to each parameter option in parameters.py . Can be specified as arbitrary keyword arguments or using the custom_fields argument. Access the custom \"date_modifier\" at runtime for the selected option, and use it to transform some date string. More details on squirrel's date modifiers can be found in the how-to guide for Modify Dates Using Squirrel's dateutils . Custom fields can also come from lookup tables as \"custom columns\" when using the custom_cols argument in the constructor of SelectionDataSource for a DataSourceParameter .","title":"Set Parameter Option Custom Fields"},{"location":"how-to/custom-fields/#1-associating-custom-fields-to-parameter-options","text":"In parameters.py , you can use arbitrary keyword arguments as follows to specify custom fields. Note the date_modifier keyword arguments to SelectParameterOption . from squirrels import dateutils as du import squirrels as sr ... ytd_date_modifier = du.DateStringModifier([du.DayIdxOfYear(1)]) yoy_date_modifier = du.DateStringModifier([du.OffsetYears(-1)]) time_period_options = [ sr.SelectParameterOption(\"t0\", \"Year to Date\", date_modifier=ytd_date_modifier), sr.SelectParameterOption(\"t1\", \"Year over Year\", date_modifier=yoy_date_modifier) ] time_period_param = sr.SingleSelectParameter(\"time_period\", \"Time Period\", time_period_options) You can also specify custom fields as a dictionary using the custom_fields argument. This is an alternative example for \"Year to Date\": sr.SelectParameterOption(\"t0\", \"Year to Date\", custom_fields={\"date_modifier\":ytd_date_modifier})","title":"1. Associating Custom Fields to Parameter Options"},{"location":"how-to/custom-fields/#2-access-the-custom-fields-at-runtime","text":"You can get the date modifier(s) of the selected option(s) using the get_selected method for SingleSelectParameter (returns one value) or the get_selected_list method for MultiSelectParameter (returns a list of values). Both methods take a string argument called field (first positional argument) that lets you get the custom field(s) for the selected option(s). If the field is not specified, the methods return the SelectParameterOption object(s) instead. Assume we have a date string to modify called latest_date (perhaps derived from another parameter). The following example applies the selected date_modifier of the \"time_period\" parameter to latest_date , which can be done purely in Python in the context.py file. time_period_param: sr.SingleSelectParameter = prms[\"time_period\"] date_modifier = time_period_param.get_selected(\"date_modifier\") start_date = date_modifier.modify(latest_date) Alternatively, the selected date_modifier can also be accessed like this: date_modifier = time_period_param.get_selected().custom_fields[\"date_modifier\"] Note If you prefer to not use context.py , variables can be set in the Jinja SQL views with {% set var_name = ... %} .","title":"2. Access the Custom Fields at Runtime"},{"location":"how-to/custom-fields/#specifying-custom-columns-for-datasourceparameter","text":"Instead of using a date_modifier , suppose that the start date comes from a lookup table in the database instead. For instance, the lookup table can look like the following where the \"start_date_column\" gets updated regularly. time_period_id time_period_label start_date_column t0 Year to Date 2023-01-01 t1 Year over Year 2022-07-02 Instead of specifying a SingleSelectParameter for time_period_param , it can be a DataSourceParameter (using custom_cols ) that converts itself into a SingleSelectParameter instead. time_period_ds = sr.SelectionDataSource(\"time_period_table\", \"time_period_id\", \"time_period_label\", custom_cols={\"start_date\": \"start_date_column\"}) time_period_param = sr.DataSourceParameter(sr.SingleSelectParameter, \"time_period\", \"Time Period\", time_period_ds) Then, in context.py , the selected start date can be accessed as follows. time_period_param: sr.SingleSelectParameter = prms[\"time_period\"] start_date = time_period_param.get_selected(\"start_date\")","title":"Specifying Custom Columns for DataSourceParameter"},{"location":"how-to/database/","text":"Configure Database Connections All database connections are currently handled by sqlalchemy in the current version, with future expansion into no-sql databases on the horizon. Database connections in the squirrels framework can be added and configured either in the connections.py file, or under the db_connections field in the manifest file ( squirrels.yaml ). These two options are provided to allow for greater flexibility in terms of project design, and one can work without the other. Adding a database connection in squirrels.yaml To add a database connection in the squirrels.yaml file, you'll need to add the connection in the form of a collection under db_connections . There are two things that you'll need to add: The name of the connection. This is the name that we'll refer to for this connection in the other files. Under the name that defines the collection, you'll need to provided a sqlalchemy url named url The syntax for the URL uses sqlalchemy database URLs . If you decide to use credentials, you'll also need to provide a credential_key in the field as well. Credentials can be set using the squirrels set-credential command covered here: credential management The db_connections section should look something like this: db_connections: # optional if connections.py exists default: url: 'sqlite:///./database/seattle_weather.db' If you decide to use credentials, a new field for the credential_key should be provided, and depending on the type of database used, masks for username and password can also be used. This should look something like below. db_connections: # optional if connections.py exists default: credential_key: example # optional if null url: 'sqlite://${username}:${password}@/./database/sample_database.db' A connection named \"default\" must be specified here unless it's specified in the connections.py file. Any database view or DataSource parameter that doesn't specify a database connection will use \"default\". Adding a database connection in the connections.py file To add a connection in the connections.py file, you'll need to create a connection engine/pool using the same sqlalchemy URL as one would do in the squirrels.yaml file as well. Again, the schema for the URL can be found here: sqlalchemy database URLs . After that's created, it will then need to be passed to the return statement in the form of a python dictionary, where the key corresponding to the connection engine is the name that should be referred to in the db_connection field under each dataset in the squirrels.yaml files. If credentials are needed, they can also be added by providing the credential key to the get_credential function. And the username and passwords can be accessed with cred.username and cred.password respectively. Refer to the SQLAlchemy URL guide on how to use the credentials in the urls. The squirrel framework also allows the user to use a QueuePool in place of the create_engine function. def main(proj: Dict[str, Any], *p_args, **kwargs) -> Dict[str, Union[Engine, Pool]]: ## Example of getting the username and password set with \"$ squirrels set-credential [key]\" # cred = get_credential('my_key') # then use cred.username and cred.password to access the username and password # Create a connection pool / engine pool = create_engine('sqlite:///./database/sample_database.db') ## Example of using QueuePool instead for a custom db connector: # connection_creator = lambda: sqlite3.connect('./database/sample_database.db', check_same_thread=False) # pool = QueuePool(connection_creator) return {'default': pool} A connection named \"default\" must be specified here unless it's specified in the squirrels.yaml file. Any database view or DataSource parameter that doesn't specify a database connection will use \"default\".","title":"Configure Database Connections"},{"location":"how-to/database/#configure-database-connections","text":"All database connections are currently handled by sqlalchemy in the current version, with future expansion into no-sql databases on the horizon. Database connections in the squirrels framework can be added and configured either in the connections.py file, or under the db_connections field in the manifest file ( squirrels.yaml ). These two options are provided to allow for greater flexibility in terms of project design, and one can work without the other.","title":"Configure Database Connections"},{"location":"how-to/database/#adding-a-database-connection-in-squirrelsyaml","text":"To add a database connection in the squirrels.yaml file, you'll need to add the connection in the form of a collection under db_connections . There are two things that you'll need to add: The name of the connection. This is the name that we'll refer to for this connection in the other files. Under the name that defines the collection, you'll need to provided a sqlalchemy url named url The syntax for the URL uses sqlalchemy database URLs . If you decide to use credentials, you'll also need to provide a credential_key in the field as well. Credentials can be set using the squirrels set-credential command covered here: credential management The db_connections section should look something like this: db_connections: # optional if connections.py exists default: url: 'sqlite:///./database/seattle_weather.db' If you decide to use credentials, a new field for the credential_key should be provided, and depending on the type of database used, masks for username and password can also be used. This should look something like below. db_connections: # optional if connections.py exists default: credential_key: example # optional if null url: 'sqlite://${username}:${password}@/./database/sample_database.db' A connection named \"default\" must be specified here unless it's specified in the connections.py file. Any database view or DataSource parameter that doesn't specify a database connection will use \"default\".","title":"Adding a database connection in squirrels.yaml"},{"location":"how-to/database/#adding-a-database-connection-in-the-connectionspy-file","text":"To add a connection in the connections.py file, you'll need to create a connection engine/pool using the same sqlalchemy URL as one would do in the squirrels.yaml file as well. Again, the schema for the URL can be found here: sqlalchemy database URLs . After that's created, it will then need to be passed to the return statement in the form of a python dictionary, where the key corresponding to the connection engine is the name that should be referred to in the db_connection field under each dataset in the squirrels.yaml files. If credentials are needed, they can also be added by providing the credential key to the get_credential function. And the username and passwords can be accessed with cred.username and cred.password respectively. Refer to the SQLAlchemy URL guide on how to use the credentials in the urls. The squirrel framework also allows the user to use a QueuePool in place of the create_engine function. def main(proj: Dict[str, Any], *p_args, **kwargs) -> Dict[str, Union[Engine, Pool]]: ## Example of getting the username and password set with \"$ squirrels set-credential [key]\" # cred = get_credential('my_key') # then use cred.username and cred.password to access the username and password # Create a connection pool / engine pool = create_engine('sqlite:///./database/sample_database.db') ## Example of using QueuePool instead for a custom db connector: # connection_creator = lambda: sqlite3.connect('./database/sample_database.db', check_same_thread=False) # pool = QueuePool(connection_creator) return {'default': pool} A connection named \"default\" must be specified here unless it's specified in the squirrels.yaml file. Any database view or DataSource parameter that doesn't specify a database connection will use \"default\".","title":"Adding a database connection in the connections.py file"},{"location":"how-to/modify-dates/","text":"Modify Dates Using Squirrel's dateutils The squirrels library has a submodule called dateutils that can be used to transform date variables in Python with ease. To import the dateutils module, simply do: from squirrels import dateutils as du The examples below demonstrates how to modify a given date by number of time periods and/or get some day of a calendar cycle. The format of the date can be datetime objects, string dates, or unix timestamps (as float). Assume we have a datetime object variable called date_obj . Offset by Time Period The following classes can be used to offset a datetime object by some time period. OffsetYears OffsetMonths OffsetWeeks OffsetDays Each of their constructors take an argument offset for the number of time periods to offset by (can be positive or negative), and each class contains a modify method to modify an input date. To add 3 weeks to date_obj , the code you write can look something like this: new_date = OffsetWeeks(3).modify(date_obj) Get N-th Day of Calendar Cycle The following classes can be used to get a certain day of some calendar cycle from some datetime object. DayIdxOfMonthsCycle DayIdxOfYear DayIdxOfQuarter DayIdxOfMonth DayIdxOfWeek Each of their constuctors take an parameter idx to specify the day number of cycle. Positive numbers like 1 and 2 represent the first and second day, while negative numbers like -1 and -2 represent the last and second last day. 0 cannot be used. For DayIdxOfMonthsCycle, the length of the cycle in months can be specified with the parameter num_months_in_cycle . This is unlike DayIdxOfMonth where the length of the cycle is always one month. DayIdxOfYear, DayIdxOfQuarter, and DayIdxOfMonth are equivalent to DayIdxOfMonthsCycle when the num_months_in_cycle values 12, 3, and 1 respectively. For DayIdxOfWeek, the first day of the week (using the DayOfWeek enum which contains values Monday, Tuesday, etc. until Sunday) can be specified using the first_day_of_week parameter. The first month of the year can be specified (using the Month enum which contains values January, February, etc. until December) with the parameter first_month_of_X where X is \"cycle\", \"year\", and \"quarter\" for DayIdxOfMonthsCycle, DayIdxOfYear, and DayIdxOfQuarter respectively. Each of these classes contain a modify method to modify an input date as well. Here are some problems and solutions in code using these classes. Problem Solution Get the same or prior Friday DayIdxOfWeek(idx=1, first_day_of_week=DayOfWeek.Friday).modify(date_obj) Get the same or next Friday DayIdxOfWeek(idx=-1, first_day_of_week=DayOfWeek.Saturday).modify(date_obj) If Wednesday to Friday, round up to Friday. Otherwise round down to Friday DayIdxOfWeek(idx=3, first_day_of_week=DayOfWeek.Wednesday).modify(date_obj) Get the third last day of month DayIdxOfMonth(idx=-3).modify(date_obj) Suppose a \"Third Year\" occurs every 4 months from February 1st. Get the beginning of current Third Year DayIdxOfMonthsCycle(idx=1, num_months_in_cycle=4, first_month_of_cycle=Month.February).modify(date_obj) Date Modification Pipeline A class called DateModPipeline lets you stitch together multiple instances of the date modification classes above into a single date modification class. Simply specify a sequence of date modification class instances in the constructor. Using this pipeline approach allows one to make almost any date transformation possible. Here are some more examples of problems and solutions. Problem Solution Get the next Friday DateModPipeline([DayIdxOfWeek(1, DayOfWeek.Friday), OffsetWeeks(1)]).modify(date_obj) Get the prior Friday DateModPipeline([DayIdxOfWeek(-1, DayOfWeek.Saturday), OffsetWeeks(-1)]).modify(date_obj) Get the second Friday of the current quarter. First month of quarter is January DateModPipeline([DayIdxOfQuarter(1), DayIdxOfWeek(-1, DayOfWeek.Saturday), OffsetWeeks(1)]).modify(date_obj) In addition to the modify method, this class also lets you get a list of date objects with the method get_date_list . It takes an input start date and a step (as an Offset* date modifier), modifies the start date to get the end date, and returns the dates from start to end by step. Below is an example of getting every Friday going back from June 15th 2023 to beginning of Quarter. modifier = DateModPipeline([DayIdxOfQuarter(1), DayIdxOfWeek(-1, DayOfWeek.Saturday)]) date_list = modifier.get_date_list(datetime(2023, 6, 15), OffsetWeeks(-1)) Modifying Date Strings or Timestamps More often then not, the dates that you're working with are date formatted strings or timestamps as floats. Although it should be easy enough to convert to datetime object and back, the dateutils module also provides DateStringModifier and TimestampModifier classes to simplify your code. Just like DateModPipeline , both these classes have a constructor that takes a sequence of date modification class instances, a modify method, and a get_date_list method. For DateStringModifier , the constructor also takes an optional date_format argument for the date format of the outputs. The methods modify and get_date_list take an input date as string, and an optional input_format argument for the date format of the input date. For TimestampModifier , the input date for methods modify and get_date_list are floats representing the UNIX timestamp of the date. The output dates are also in the same format.","title":"Modify Dates Using Squirrel's dateutils"},{"location":"how-to/modify-dates/#modify-dates-using-squirrels-dateutils","text":"The squirrels library has a submodule called dateutils that can be used to transform date variables in Python with ease. To import the dateutils module, simply do: from squirrels import dateutils as du The examples below demonstrates how to modify a given date by number of time periods and/or get some day of a calendar cycle. The format of the date can be datetime objects, string dates, or unix timestamps (as float). Assume we have a datetime object variable called date_obj .","title":"Modify Dates Using Squirrel's dateutils"},{"location":"how-to/modify-dates/#offset-by-time-period","text":"The following classes can be used to offset a datetime object by some time period. OffsetYears OffsetMonths OffsetWeeks OffsetDays Each of their constructors take an argument offset for the number of time periods to offset by (can be positive or negative), and each class contains a modify method to modify an input date. To add 3 weeks to date_obj , the code you write can look something like this: new_date = OffsetWeeks(3).modify(date_obj)","title":"Offset by Time Period"},{"location":"how-to/modify-dates/#get-n-th-day-of-calendar-cycle","text":"The following classes can be used to get a certain day of some calendar cycle from some datetime object. DayIdxOfMonthsCycle DayIdxOfYear DayIdxOfQuarter DayIdxOfMonth DayIdxOfWeek Each of their constuctors take an parameter idx to specify the day number of cycle. Positive numbers like 1 and 2 represent the first and second day, while negative numbers like -1 and -2 represent the last and second last day. 0 cannot be used. For DayIdxOfMonthsCycle, the length of the cycle in months can be specified with the parameter num_months_in_cycle . This is unlike DayIdxOfMonth where the length of the cycle is always one month. DayIdxOfYear, DayIdxOfQuarter, and DayIdxOfMonth are equivalent to DayIdxOfMonthsCycle when the num_months_in_cycle values 12, 3, and 1 respectively. For DayIdxOfWeek, the first day of the week (using the DayOfWeek enum which contains values Monday, Tuesday, etc. until Sunday) can be specified using the first_day_of_week parameter. The first month of the year can be specified (using the Month enum which contains values January, February, etc. until December) with the parameter first_month_of_X where X is \"cycle\", \"year\", and \"quarter\" for DayIdxOfMonthsCycle, DayIdxOfYear, and DayIdxOfQuarter respectively. Each of these classes contain a modify method to modify an input date as well. Here are some problems and solutions in code using these classes. Problem Solution Get the same or prior Friday DayIdxOfWeek(idx=1, first_day_of_week=DayOfWeek.Friday).modify(date_obj) Get the same or next Friday DayIdxOfWeek(idx=-1, first_day_of_week=DayOfWeek.Saturday).modify(date_obj) If Wednesday to Friday, round up to Friday. Otherwise round down to Friday DayIdxOfWeek(idx=3, first_day_of_week=DayOfWeek.Wednesday).modify(date_obj) Get the third last day of month DayIdxOfMonth(idx=-3).modify(date_obj) Suppose a \"Third Year\" occurs every 4 months from February 1st. Get the beginning of current Third Year DayIdxOfMonthsCycle(idx=1, num_months_in_cycle=4, first_month_of_cycle=Month.February).modify(date_obj)","title":"Get N-th Day of Calendar Cycle"},{"location":"how-to/modify-dates/#date-modification-pipeline","text":"A class called DateModPipeline lets you stitch together multiple instances of the date modification classes above into a single date modification class. Simply specify a sequence of date modification class instances in the constructor. Using this pipeline approach allows one to make almost any date transformation possible. Here are some more examples of problems and solutions. Problem Solution Get the next Friday DateModPipeline([DayIdxOfWeek(1, DayOfWeek.Friday), OffsetWeeks(1)]).modify(date_obj) Get the prior Friday DateModPipeline([DayIdxOfWeek(-1, DayOfWeek.Saturday), OffsetWeeks(-1)]).modify(date_obj) Get the second Friday of the current quarter. First month of quarter is January DateModPipeline([DayIdxOfQuarter(1), DayIdxOfWeek(-1, DayOfWeek.Saturday), OffsetWeeks(1)]).modify(date_obj) In addition to the modify method, this class also lets you get a list of date objects with the method get_date_list . It takes an input start date and a step (as an Offset* date modifier), modifies the start date to get the end date, and returns the dates from start to end by step. Below is an example of getting every Friday going back from June 15th 2023 to beginning of Quarter. modifier = DateModPipeline([DayIdxOfQuarter(1), DayIdxOfWeek(-1, DayOfWeek.Saturday)]) date_list = modifier.get_date_list(datetime(2023, 6, 15), OffsetWeeks(-1))","title":"Date Modification Pipeline"},{"location":"how-to/modify-dates/#modifying-date-strings-or-timestamps","text":"More often then not, the dates that you're working with are date formatted strings or timestamps as floats. Although it should be easy enough to convert to datetime object and back, the dateutils module also provides DateStringModifier and TimestampModifier classes to simplify your code. Just like DateModPipeline , both these classes have a constructor that takes a sequence of date modification class instances, a modify method, and a get_date_list method. For DateStringModifier , the constructor also takes an optional date_format argument for the date format of the outputs. The methods modify and get_date_list take an input date as string, and an optional input_format argument for the date format of the input date. For TimestampModifier , the input date for methods modify and get_date_list are floats representing the UNIX timestamp of the date. The output dates are also in the same format.","title":"Modifying Date Strings or Timestamps"},{"location":"how-to/python-views/","text":"Create Views with Python Note : This is the Python version of how to create views, for the SQL template version see: Create Views with SQL and Jinja There are two types of views that are relavent to a squirrels project: database views, and final views. The \"database view\" refers to the view that's directly selected from the database using a connection as described here Creating a Database Connection , while on the other hand, the final view query joins the database views to generate the final dataset that is sent to the front end. Creating a database view Regardless whether you use Python or SQL for your database view, you'll need create the parameters in the parameters.py file. This is delineated here: Creating Parameters . After that's done, these are the following steps to create views with python: Create sample file by running the following command in the terminal: squirrels init --core --db-view py for creating a database view, squirrels init --final-view py for creating a final view. Copy over the file from the sample_dataset folder to your desired dataset folder, and rename the file accordingly. Update the file name in squirrels.yaml to the name of the file you've just coppied over. Populate the file with the query template for your dataset. Creating an empty file and copying (Step 1 - 2) Run the squirrels init --core --db-view py command to create a database_view1.py file in the sample_dataset folder, or run squirrels init --final-view py to create a final_view.py file. These files can then serve as templates for the subsequent SQL database views that you'll need to create for your project. After you've created and located the file(s), you can then copy it over to your desired dataset folder, and rename your file(s) accordingly. Adding the view to squirrels.yaml (Step 3) After a view has been created, regardless of whether it's using SQL or Python, the views will need to be added to the manifest files in order for the project to be able to see the files. Under datasets , add a name for the dataset folder the views are housed in, and provide the label for the dataset. Under database_views , provide each database views' file name, name of the connection under db_connection , and any additional arguments. Make sure to add the file suffixes. The datasets field should have at least this much: datasets: <your_dataset>: label: <your_dataset label> database_views: database_view1: file: <new_database_view_name>.sql.j2 db_connection: default # optional if default args: {} # optional if empty final_view: <new_final_view_name>.sql.j2 args: {} # optional if empty Populating the file (Step 4) Inside the main() function for the database view, you'll be able to access the database connection by first using connection_set.get_connection_pool(\"<connection_name>\") to get the connection pool/sqlalchemy engine (from which you can get a DBAPI/sqlalchemy connection to query databases), and create a pandas dataframes out of it to return as output. On the other hand, the final view holds whatever additional transformation that needs to happen after the queries for the database views have been returned. The results from the database views are stored in the database_views dictionary, and individual dataframes can be retrieved by referring to the name of the view. The final view is not strictly needed, but can be useful depending on the project. Both the final and database views have access to the following keywords: prms ctx args The first prms variable contains all the parameters as specificed and returned in the parameters.py file in the form of a dictionary, where the key is the name of the parameter (the first argument passed into the parameter's constructor). The values selected from the parameters can be retrieved by using a method that starts with \"get_selected_\". The available \"get_selected_\" method(s) depend on the type of the parameter (for instance, SingleSelectParameter has get_selected_id , get_selected_label , and more). The ctx variable is a dictionary as well, returned by context.py , to create any derived value from the parameter selections. The args is also a similar dictionary, but contains the project information in the squirrels.yaml file, see Manifest File (squirrels.yaml) for more information. A parameter can be retrieved in the template like a standard Python map within a double curly bracket {{}} by specifying the key like prms['single_select_param'] , and calling a method for the selected parameter, such as prms['single_select_param'].get_selected_label_quoted() .","title":"Create Views with Python"},{"location":"how-to/python-views/#create-views-with-python","text":"Note : This is the Python version of how to create views, for the SQL template version see: Create Views with SQL and Jinja There are two types of views that are relavent to a squirrels project: database views, and final views. The \"database view\" refers to the view that's directly selected from the database using a connection as described here Creating a Database Connection , while on the other hand, the final view query joins the database views to generate the final dataset that is sent to the front end.","title":"Create Views with Python"},{"location":"how-to/python-views/#creating-a-database-view","text":"Regardless whether you use Python or SQL for your database view, you'll need create the parameters in the parameters.py file. This is delineated here: Creating Parameters . After that's done, these are the following steps to create views with python: Create sample file by running the following command in the terminal: squirrels init --core --db-view py for creating a database view, squirrels init --final-view py for creating a final view. Copy over the file from the sample_dataset folder to your desired dataset folder, and rename the file accordingly. Update the file name in squirrels.yaml to the name of the file you've just coppied over. Populate the file with the query template for your dataset.","title":"Creating a database view"},{"location":"how-to/python-views/#creating-an-empty-file-and-copying-step-1-2","text":"Run the squirrels init --core --db-view py command to create a database_view1.py file in the sample_dataset folder, or run squirrels init --final-view py to create a final_view.py file. These files can then serve as templates for the subsequent SQL database views that you'll need to create for your project. After you've created and located the file(s), you can then copy it over to your desired dataset folder, and rename your file(s) accordingly.","title":"Creating an empty file and copying (Step 1 - 2)"},{"location":"how-to/python-views/#adding-the-view-to-squirrelsyaml-step-3","text":"After a view has been created, regardless of whether it's using SQL or Python, the views will need to be added to the manifest files in order for the project to be able to see the files. Under datasets , add a name for the dataset folder the views are housed in, and provide the label for the dataset. Under database_views , provide each database views' file name, name of the connection under db_connection , and any additional arguments. Make sure to add the file suffixes. The datasets field should have at least this much: datasets: <your_dataset>: label: <your_dataset label> database_views: database_view1: file: <new_database_view_name>.sql.j2 db_connection: default # optional if default args: {} # optional if empty final_view: <new_final_view_name>.sql.j2 args: {} # optional if empty","title":"Adding the view to squirrels.yaml (Step 3)"},{"location":"how-to/python-views/#populating-the-file-step-4","text":"Inside the main() function for the database view, you'll be able to access the database connection by first using connection_set.get_connection_pool(\"<connection_name>\") to get the connection pool/sqlalchemy engine (from which you can get a DBAPI/sqlalchemy connection to query databases), and create a pandas dataframes out of it to return as output. On the other hand, the final view holds whatever additional transformation that needs to happen after the queries for the database views have been returned. The results from the database views are stored in the database_views dictionary, and individual dataframes can be retrieved by referring to the name of the view. The final view is not strictly needed, but can be useful depending on the project. Both the final and database views have access to the following keywords: prms ctx args The first prms variable contains all the parameters as specificed and returned in the parameters.py file in the form of a dictionary, where the key is the name of the parameter (the first argument passed into the parameter's constructor). The values selected from the parameters can be retrieved by using a method that starts with \"get_selected_\". The available \"get_selected_\" method(s) depend on the type of the parameter (for instance, SingleSelectParameter has get_selected_id , get_selected_label , and more). The ctx variable is a dictionary as well, returned by context.py , to create any derived value from the parameter selections. The args is also a similar dictionary, but contains the project information in the squirrels.yaml file, see Manifest File (squirrels.yaml) for more information. A parameter can be retrieved in the template like a standard Python map within a double curly bracket {{}} by specifying the key like prms['single_select_param'] , and calling a method for the selected parameter, such as prms['single_select_param'].get_selected_label_quoted() .","title":"Populating the file (Step 4)"},{"location":"how-to/sql-views/","text":"Create Views with SQL and Jinja Note : This is the SQL version of how to create views, for the Python template version see: Create Views with Python There are two types of views that are relavent to a squirrels project: database views, and final views. The \"database view\" refers to the view that's directly selected from the database using a connection as described here Creating a Database Connection , while on the other hand, the final view query joins the database views to generate the final dataset that is sent to the front end. Creating database views Regardless whether you use Python or SQL for your database view, you'll need create the parameters in the parameters.py file. This is delineated here: Creating Parameters . To create a database view, here are a few simple steps to follow: Create sample file by using squirrels init . Copy over the file from the sample_dataset folder to your desired dataset folder, and rename the file accordingly. Update the file name in squirrels.yaml to the name of the file you've just copied over. Populate the file with the query template for your dataset. Creating an empty file and copying (Step 1 - 2) Run the squirrels init --core --db-view sql command to create a database_view1.sql.j2 file in the sample_dataset folder, or run squirrels init --final-view sql to create a final_view.sql.j2 file. These files can then serve as templates for the subsequent SQL database views that you'll need to create for your project. After you've created and located the file(s), you can then copy it over to your desired dataset folder, and rename your file(s) accordingly. Adding the view to squirrels.yaml (Step 3) After a view has been created, regardless of whether it's using SQL or Python, the views will need to be added to the manifest files in order for the project to be able to see the files. Under datasets , add a name for the dataset folder the views are housed in, and provide the label for the dataset. Under database_views , provide each database views' file name, name of the connection under db_connection , and any additional arguments. Make sure to add the file suffixes. The datasets field should have at least this much: datasets: <your_dataset>: label: <your_dataset label> database_views: database_view1: file: <new_database_view_name>.sql.j2 db_connection: default # optional if default args: {} # optional if empty final_view: <new_final_view_name>.sql.j2 args: {} # optional if empty Populating the file (Step 4) After you've copied over the file, feel free to delete them and make your own view from scratch. The database view queries the database, and the final view is joins all the results of the database views together in a SQLite query. Both of these views are Jinja templates for SQL, and the standard Jinja syntax applies. For database views, the specific SQL syntax is determined by the database as specified in either connection.py or squirrels.yaml . See Configure Database Connections for more details regarding database connections and how to create it. Both the final and database views have access to the following keywords: prms ctx args The first prms variable contains all the parameters as specified in the parameters.py file in the form of a dictionary, where the key is the name of the parameter (the first argument passed into the parameter's constructor). Likewise, the ctx variable is a dictionary as well consisting of parameter options returned by context.py . The args is also a similar dictionary, but contains the project information in the squirrels.yaml file, see Manifest File (squirrels.yaml) for more information on \"project variables\" and \"args\". A parameter can be retrieved in the template like a standard Python map within a double curly bracket {{}} by specifying the key like prms['single_select_param'] , and calling a method for the selected parameter, such as prms['single_select_param'].get_selected_label_quoted() . In the future, we also plan to add an optional argument analogus to the sql USE statement in the sql template in order to have a way to specify which database is to be used dynamically. Currently, it can only be specified in the squirrels.yaml file as a fixed value using db_connection .","title":"Create Views with SQL and Jinja"},{"location":"how-to/sql-views/#create-views-with-sql-and-jinja","text":"Note : This is the SQL version of how to create views, for the Python template version see: Create Views with Python There are two types of views that are relavent to a squirrels project: database views, and final views. The \"database view\" refers to the view that's directly selected from the database using a connection as described here Creating a Database Connection , while on the other hand, the final view query joins the database views to generate the final dataset that is sent to the front end.","title":"Create Views with SQL and Jinja"},{"location":"how-to/sql-views/#creating-database-views","text":"Regardless whether you use Python or SQL for your database view, you'll need create the parameters in the parameters.py file. This is delineated here: Creating Parameters . To create a database view, here are a few simple steps to follow: Create sample file by using squirrels init . Copy over the file from the sample_dataset folder to your desired dataset folder, and rename the file accordingly. Update the file name in squirrels.yaml to the name of the file you've just copied over. Populate the file with the query template for your dataset.","title":"Creating database views"},{"location":"how-to/sql-views/#creating-an-empty-file-and-copying-step-1-2","text":"Run the squirrels init --core --db-view sql command to create a database_view1.sql.j2 file in the sample_dataset folder, or run squirrels init --final-view sql to create a final_view.sql.j2 file. These files can then serve as templates for the subsequent SQL database views that you'll need to create for your project. After you've created and located the file(s), you can then copy it over to your desired dataset folder, and rename your file(s) accordingly.","title":"Creating an empty file and copying (Step 1 - 2)"},{"location":"how-to/sql-views/#adding-the-view-to-squirrelsyaml-step-3","text":"After a view has been created, regardless of whether it's using SQL or Python, the views will need to be added to the manifest files in order for the project to be able to see the files. Under datasets , add a name for the dataset folder the views are housed in, and provide the label for the dataset. Under database_views , provide each database views' file name, name of the connection under db_connection , and any additional arguments. Make sure to add the file suffixes. The datasets field should have at least this much: datasets: <your_dataset>: label: <your_dataset label> database_views: database_view1: file: <new_database_view_name>.sql.j2 db_connection: default # optional if default args: {} # optional if empty final_view: <new_final_view_name>.sql.j2 args: {} # optional if empty","title":"Adding the view to squirrels.yaml (Step 3)"},{"location":"how-to/sql-views/#populating-the-file-step-4","text":"After you've copied over the file, feel free to delete them and make your own view from scratch. The database view queries the database, and the final view is joins all the results of the database views together in a SQLite query. Both of these views are Jinja templates for SQL, and the standard Jinja syntax applies. For database views, the specific SQL syntax is determined by the database as specified in either connection.py or squirrels.yaml . See Configure Database Connections for more details regarding database connections and how to create it. Both the final and database views have access to the following keywords: prms ctx args The first prms variable contains all the parameters as specified in the parameters.py file in the form of a dictionary, where the key is the name of the parameter (the first argument passed into the parameter's constructor). Likewise, the ctx variable is a dictionary as well consisting of parameter options returned by context.py . The args is also a similar dictionary, but contains the project information in the squirrels.yaml file, see Manifest File (squirrels.yaml) for more information on \"project variables\" and \"args\". A parameter can be retrieved in the template like a standard Python map within a double curly bracket {{}} by specifying the key like prms['single_select_param'] , and calling a method for the selected parameter, such as prms['single_select_param'].get_selected_label_quoted() . In the future, we also plan to add an optional argument analogus to the sql USE statement in the sql template in order to have a way to specify which database is to be used dynamically. Currently, it can only be specified in the squirrels.yaml file as a fixed value using db_connection .","title":"Populating the file (Step 4)"},{"location":"how-to/writing-parameters/","text":"Creating Parameters Before writing the query templates, you'll need to specify the kinds of parameters that would be used. Below is an example of a parameters.py file included in the project: def main(args: Dict[str, Any], *p_args, **kwargs) -> sq.ParameterSet: single_select_options = ( sq.SelectParameterOption('a0', 'Primary Colors'), sq.SelectParameterOption('a1', 'Secondary Colors') ) multi_select_options = ( sq.SelectParameterOption('x0', 'Red', parent_option_id='a0'), sq.SelectParameterOption('x1', 'Yellow', parent_option_id='a0'), sq.SelectParameterOption('x2', 'Blue', parent_option_id='a0'), sq.SelectParameterOption('x3', 'Green', parent_option_id='a1'), sq.SelectParameterOption('x4', 'Orange', parent_option_id='a1'), sq.SelectParameterOption('x5', 'Purple', parent_option_id='a1') ) single_select_example = sq.SingleSelectParameter('color_type', 'Color Type', single_select_options) multi_select_example = sq.MultiSelectParameter('colors', 'Colors', multi_select_options, parent=single_select_example) date_example = sq.DateParameter('as_of_date', 'As Of Date', '2020-01-01') number_example = sq.NumberParameter('upper_bound', 'Upper Bound', min_value=1, max_value=10, increment=1, default_value=5) return [single_select_example, multi_select_example, date_example, number_example] Currently, there are five supported types of parameters: Single-select Parameter Multi-select Parameter Date Parameter Number Parameter DataSource Parameter In order to create a parameter, here are some basic steps: Create a parameters.py file for you dataset, this should be automatically generated in a sample dataset when you ran squirrels init . Copy/move the parameters.py file from the original sample dataset folder to your own dataset folder. In the file, create/specify your parameter options Initialize parameters Add parameter to the return list Steps 1 - 2 are self explanatory, so we will not go in detail for those. Specifying parameter options (Step 3) All parameters need options to choose from, and in the squirrels framework, most parameter options come in the form of a SelectParameterOption object, which houses all the data that pertains to that specific option, ie. its ID, label, and other custom attributes. We then use a list to contain all the parameter options for a single parameter, which will get passed through to the parameter constructor. Using the example above, the parameter options for the single-select and multi-select parameters are as following: single_select_options = ( sq.SelectParameterOption('a0', 'Primary Colors'), sq.SelectParameterOption('a1', 'Secondary Colors') ) multi_select_options = ( sq.SelectParameterOption('x0', 'Red', parent_option_id='a0'), sq.SelectParameterOption('x1', 'Yellow', parent_option_id='a0'), sq.SelectParameterOption('x2', 'Blue', parent_option_id='a0'), sq.SelectParameterOption('x3', 'Green', parent_option_id='a1'), sq.SelectParameterOption('x4', 'Orange', parent_option_id='a1'), sq.SelectParameterOption('x5', 'Purple', parent_option_id='a1') ) In the SelectParameterOption constructor, the first argument is the ID, and the next is its label. Those arguments are necessary, while the rest are optional. An example of a useful optional argument is the parent_option_id that's also in the example above. When specified, the parameter option would only show up if the parameter id with the parent_option_id is selected. If creating a DataSource parameter that converts itself into another parameter, specify a \"DataSource\" that represents the query or table name, and associate columns to specific attributes like ID and label. An example is shown where the table/query, ID column, and label column are required. category_ds = sr.SelectionDataSource(\"SELECT DISTINCT Category_ID, Category FROM categories\", \"Category_ID\", \"Category\") Creating the parameters (Step 4) After the parameter options are specified and aggregated, the list can then get passed to the parameters parameter constructor. single_select_example = sq.SingleSelectParameter('color_type', 'Color Type', single_select_options) multi_select_example = sq.MultiSelectParameter('colors', 'Colors', multi_select_options, parent=single_select_example) In general, each constructor to create a parameter object follows the following form: sq.XXXParameter(<id>, <label>, <Options>) however, please refer to the docstrings for the most up-to-date documentation on the specific functions. Note how since the multiselect parameter options uses the parent_option_id field, the call to the MultiSelectParameter's constructor also specifies the parent parameter to which the options refer. The following are examples of Date and Number parameters: date_example = sq.DateParameter('as_of_date', 'As Of Date', '2020-01-01') number_example = sq.NumberParameter('upper_bound', 'Upper Bound', min_value=1, max_value=10, increment=1, default_value=5) A DataSource parameter is a parameter that can convert itself into another parameter based on a lookup table in the database. The following example is a DataSource parameter specifying the parameter class it converts to, the ID, the label, and the selection datasource. category_filter = sr.DataSourceParameter(sr.MultiSelectParameter, \"category\", \"Category Filter\", category_ds) For more information on the Date, Number, and DataSource parameters, please refer to the docstrings. For more information on specifying custom fields on parameter options, please refer to this page for how to Set Parameter Option Custom Fields . Adding the parameters to the return set (Step 5) All parameters need to be added to return list in order to be used in the database and final views. This is very straight forward, as you simply need to aggregate all the parameters you've specified into a list, and return it. return [single_select_example, multi_select_example, date_example, number_example]","title":"Create Parameters"},{"location":"how-to/writing-parameters/#creating-parameters","text":"Before writing the query templates, you'll need to specify the kinds of parameters that would be used. Below is an example of a parameters.py file included in the project: def main(args: Dict[str, Any], *p_args, **kwargs) -> sq.ParameterSet: single_select_options = ( sq.SelectParameterOption('a0', 'Primary Colors'), sq.SelectParameterOption('a1', 'Secondary Colors') ) multi_select_options = ( sq.SelectParameterOption('x0', 'Red', parent_option_id='a0'), sq.SelectParameterOption('x1', 'Yellow', parent_option_id='a0'), sq.SelectParameterOption('x2', 'Blue', parent_option_id='a0'), sq.SelectParameterOption('x3', 'Green', parent_option_id='a1'), sq.SelectParameterOption('x4', 'Orange', parent_option_id='a1'), sq.SelectParameterOption('x5', 'Purple', parent_option_id='a1') ) single_select_example = sq.SingleSelectParameter('color_type', 'Color Type', single_select_options) multi_select_example = sq.MultiSelectParameter('colors', 'Colors', multi_select_options, parent=single_select_example) date_example = sq.DateParameter('as_of_date', 'As Of Date', '2020-01-01') number_example = sq.NumberParameter('upper_bound', 'Upper Bound', min_value=1, max_value=10, increment=1, default_value=5) return [single_select_example, multi_select_example, date_example, number_example] Currently, there are five supported types of parameters: Single-select Parameter Multi-select Parameter Date Parameter Number Parameter DataSource Parameter In order to create a parameter, here are some basic steps: Create a parameters.py file for you dataset, this should be automatically generated in a sample dataset when you ran squirrels init . Copy/move the parameters.py file from the original sample dataset folder to your own dataset folder. In the file, create/specify your parameter options Initialize parameters Add parameter to the return list Steps 1 - 2 are self explanatory, so we will not go in detail for those.","title":"Creating Parameters"},{"location":"how-to/writing-parameters/#specifying-parameter-options-step-3","text":"All parameters need options to choose from, and in the squirrels framework, most parameter options come in the form of a SelectParameterOption object, which houses all the data that pertains to that specific option, ie. its ID, label, and other custom attributes. We then use a list to contain all the parameter options for a single parameter, which will get passed through to the parameter constructor. Using the example above, the parameter options for the single-select and multi-select parameters are as following: single_select_options = ( sq.SelectParameterOption('a0', 'Primary Colors'), sq.SelectParameterOption('a1', 'Secondary Colors') ) multi_select_options = ( sq.SelectParameterOption('x0', 'Red', parent_option_id='a0'), sq.SelectParameterOption('x1', 'Yellow', parent_option_id='a0'), sq.SelectParameterOption('x2', 'Blue', parent_option_id='a0'), sq.SelectParameterOption('x3', 'Green', parent_option_id='a1'), sq.SelectParameterOption('x4', 'Orange', parent_option_id='a1'), sq.SelectParameterOption('x5', 'Purple', parent_option_id='a1') ) In the SelectParameterOption constructor, the first argument is the ID, and the next is its label. Those arguments are necessary, while the rest are optional. An example of a useful optional argument is the parent_option_id that's also in the example above. When specified, the parameter option would only show up if the parameter id with the parent_option_id is selected. If creating a DataSource parameter that converts itself into another parameter, specify a \"DataSource\" that represents the query or table name, and associate columns to specific attributes like ID and label. An example is shown where the table/query, ID column, and label column are required. category_ds = sr.SelectionDataSource(\"SELECT DISTINCT Category_ID, Category FROM categories\", \"Category_ID\", \"Category\")","title":"Specifying parameter options (Step 3)"},{"location":"how-to/writing-parameters/#creating-the-parameters-step-4","text":"After the parameter options are specified and aggregated, the list can then get passed to the parameters parameter constructor. single_select_example = sq.SingleSelectParameter('color_type', 'Color Type', single_select_options) multi_select_example = sq.MultiSelectParameter('colors', 'Colors', multi_select_options, parent=single_select_example) In general, each constructor to create a parameter object follows the following form: sq.XXXParameter(<id>, <label>, <Options>) however, please refer to the docstrings for the most up-to-date documentation on the specific functions. Note how since the multiselect parameter options uses the parent_option_id field, the call to the MultiSelectParameter's constructor also specifies the parent parameter to which the options refer. The following are examples of Date and Number parameters: date_example = sq.DateParameter('as_of_date', 'As Of Date', '2020-01-01') number_example = sq.NumberParameter('upper_bound', 'Upper Bound', min_value=1, max_value=10, increment=1, default_value=5) A DataSource parameter is a parameter that can convert itself into another parameter based on a lookup table in the database. The following example is a DataSource parameter specifying the parameter class it converts to, the ID, the label, and the selection datasource. category_filter = sr.DataSourceParameter(sr.MultiSelectParameter, \"category\", \"Category Filter\", category_ds) For more information on the Date, Number, and DataSource parameters, please refer to the docstrings. For more information on specifying custom fields on parameter options, please refer to this page for how to Set Parameter Option Custom Fields .","title":"Creating the parameters (Step 4)"},{"location":"how-to/writing-parameters/#adding-the-parameters-to-the-return-set-step-5","text":"All parameters need to be added to return list in order to be used in the database and final views. This is very straight forward, as you simply need to aggregate all the parameters you've specified into a list, and return it. return [single_select_example, multi_select_example, date_example, number_example]","title":"Adding the parameters to the return set (Step 5)"},{"location":"release-notes/v-0-1-0/","text":"Version 0.1.0 (June 11, 2023) Initial version. Contributors Tim Huang Peter Yang","title":"Version 0.1.0 (June 11, 2023)"},{"location":"release-notes/v-0-1-0/#version-010-june-11-2023","text":"Initial version.","title":"Version 0.1.0 (June 11, 2023)"},{"location":"release-notes/v-0-1-0/#contributors","text":"Tim Huang Peter Yang","title":"Contributors"},{"location":"release-notes/v-0-1-1/","text":"Version 0.1.1 (July 2, 2023) Bug Fixes For DataSource classes, SELECT statements with leading spaces were not properly identified as SELECT queries. This is now fixed. New Features Reconstructed sample_database example from squirrels init to analyze transactions (better real-world use case). Added get_date_list method to DateModPipeline , DateStringModifier , and TimestampModifier classes in the dateutils module. Added custom_fields attribute to SelectParameterOption . Custom fields can be added to the constructor as keyword arguments or a dictionary to argument \"custom_fields\". Added custom_cols attribute to SelectionDataSource . This is a dictionary of custom field name to column where each row in the lookup table gets converted to a custom field. Added optional argument field to SingleSelectParameter's get_selected method and MultiSelectParameter's get_selected_list method. This lets you get the selected custom field, id, or label. Added optional arguments default_field and default to SingleSelectParameter's get_selected method and MultiSelectParameter's get_selected_list method, which only applies if field is specified but does not exist for the selected SelectParameterOption(s) . Contributors Tim Huang Peter Yang","title":"Version 0.1.1 (July 2, 2023)"},{"location":"release-notes/v-0-1-1/#version-011-july-2-2023","text":"","title":"Version 0.1.1 (July 2, 2023)"},{"location":"release-notes/v-0-1-1/#bug-fixes","text":"For DataSource classes, SELECT statements with leading spaces were not properly identified as SELECT queries. This is now fixed.","title":"Bug Fixes"},{"location":"release-notes/v-0-1-1/#new-features","text":"Reconstructed sample_database example from squirrels init to analyze transactions (better real-world use case). Added get_date_list method to DateModPipeline , DateStringModifier , and TimestampModifier classes in the dateutils module. Added custom_fields attribute to SelectParameterOption . Custom fields can be added to the constructor as keyword arguments or a dictionary to argument \"custom_fields\". Added custom_cols attribute to SelectionDataSource . This is a dictionary of custom field name to column where each row in the lookup table gets converted to a custom field. Added optional argument field to SingleSelectParameter's get_selected method and MultiSelectParameter's get_selected_list method. This lets you get the selected custom field, id, or label. Added optional arguments default_field and default to SingleSelectParameter's get_selected method and MultiSelectParameter's get_selected_list method, which only applies if field is specified but does not exist for the selected SelectParameterOption(s) .","title":"New Features"},{"location":"release-notes/v-0-1-1/#contributors","text":"Tim Huang Peter Yang","title":"Contributors"},{"location":"topics/manifest/","text":"Manifest File (squirrels.yaml) The manifest file contains the following sections that is described in detail below. modules project_variables db_connections datasets settings modules This section is used to specify the list of git repos (with tag) that the project uses as modules. This can be useful to share the same Python code or Jinja macros across projects. See the load-modules CLI guide for details. project_variables This section contains project variables that can be referenced within the project. The project variables \"product\", \"major_version\", and \"minor_version\" are mandatory, and they must be of type string, integer, and integer respectively. Additional custom project variables can also be added. See example below: project_variables: product: sample major_version: 1 minor_version: 0 custom_var: example The product and major_version are used in forming the appropriate REST API paths. In the future, a deployment service will use the product, major_version, and minor_version to update a catalog of products and versions available which can then be retrieved using the catalog API (more details of the catalog API are provided in the Response Schema front-end guide). Then, for the parameters or dataset paths, a request header called \"x-minor-version\" can be used to control the minor version used (or latest is used if omitted). For information incrementing major version vs minor version best practices, see the Major vs Minor Version topic guide. db_connections This section can be used to specify database connections by providing a map between keys and SQLAlchemy Database URLs . This section is optional if connections.py is provided, and both can be used at the same time (though connections.py takes precedence if there are common keys). And example of the section may look something like this: db_connections: default: url: 'dialect+driver:////absolute/path/to/database1.db' custom_db_conn_key: url: 'dialect+driver:///./relative/path/to/database2.db' Between this section and connections.py, the key \"default\" must be specified if any connection key is specified (it is possible to not specify any connection keys for certain use cases without database views in SQL). If a username and password is required in the URL, then they can be set using squirrels set-credential <key> with some credential key (see the [Credential Management CLI guide]). Then, you can specify the credential key under the connection key with the attribute credential_key and use the placeholders ${username} and ${password} in the URL. If credential_key is null or not set, the ${username} and ${password} placeholders will become empty strings. See example below for specifying a connection key with credentials. db_connections: default: credential_key: some_key url: 'dialect+driver://${username}:${password}@//path/to/database1.db' For details on using a connections.py file, see the Configure Database Connections how-to guide. datasets In this section, the list of dataset names and dataset attributes can be defined. Under each dataset name, the attributes are the label , database_views , final_view , and args . Any dataset name specified here must also have the same folder name in the datasets folder. The label is simply the display name for the dataset to appear as in a dropdown menu. This attribute is required. The database_views specifies the list of database view names and database view attributes can be defined. This attribute can be optional if no database views are required. Under the database view name, the required attribute is file , and optional attributes are db_connection and args . Or for simplicity, the value mapped to the database view name can also be a string for the equivalent file attribute. - The file must be a Jinja SQL or Python file relative to the dataset folder. - The db_connection is the database connection defined in the db_connections section or connections.py. If db_connection is not specified, it defaults to \"default\". - The args is for specifying arguments at the database view level, and can override arguments specified at the project level or dataset level. These arguments can be referenced by any database view or final view file. The final_view represents the final query for the dataset. It can be a Jinja SQL or Python file relative to the dataset folder (which can reference the results of the database views), or it can be the name of a database view. This attribute is required. The args attribute is for specifying arguments at the dataset level, and can override arguments specified at the project level (i.e., the project variables). This attribute is optional. Below shows an example of using the datasets section to construct a single sample dataset with 2 database views. datasets: sample_dataset: label: Sample Dataset database_views: database_view1: file: db_view1.sql.j2 db_connection: custom_db_conn_key args: arg1: db_view_val1 arg2: db_view_val2 database_view2: db_view2.py final_view: final_view.sql.j2 args: arg0: dataset_val0 arg1: dataset_val1 settings Certain settings can be specified in this setting. This section is optional if no settings need to be changed from their defaults. Below is an example of using this section. settings: parameters.cache.size: 1024 parameters.cache.ttl: 86400 Here are the current list of setting keys available. Deafult is used when the key is not specified. Setting Key Default Description parameters.cache.size 1024 The maximum number of responses that the LRU cache of the parameters API can store parameters.cache.ttl 86400 The time to live (in seconds) for the LRU cache of the parameters API. Default is 1 day results.cache.size 128 The maximum number of responses that the LRU cache of the results API can store results.cache.ttl 3600 The time to live (in seconds) for the LRU cache of the results API. Default is 1 hour","title":"Manifest File (squirrels.yaml)"},{"location":"topics/manifest/#manifest-file-squirrelsyaml","text":"The manifest file contains the following sections that is described in detail below. modules project_variables db_connections datasets settings","title":"Manifest File (squirrels.yaml)"},{"location":"topics/manifest/#modules","text":"This section is used to specify the list of git repos (with tag) that the project uses as modules. This can be useful to share the same Python code or Jinja macros across projects. See the load-modules CLI guide for details.","title":"modules"},{"location":"topics/manifest/#project_variables","text":"This section contains project variables that can be referenced within the project. The project variables \"product\", \"major_version\", and \"minor_version\" are mandatory, and they must be of type string, integer, and integer respectively. Additional custom project variables can also be added. See example below: project_variables: product: sample major_version: 1 minor_version: 0 custom_var: example The product and major_version are used in forming the appropriate REST API paths. In the future, a deployment service will use the product, major_version, and minor_version to update a catalog of products and versions available which can then be retrieved using the catalog API (more details of the catalog API are provided in the Response Schema front-end guide). Then, for the parameters or dataset paths, a request header called \"x-minor-version\" can be used to control the minor version used (or latest is used if omitted). For information incrementing major version vs minor version best practices, see the Major vs Minor Version topic guide.","title":"project_variables"},{"location":"topics/manifest/#db_connections","text":"This section can be used to specify database connections by providing a map between keys and SQLAlchemy Database URLs . This section is optional if connections.py is provided, and both can be used at the same time (though connections.py takes precedence if there are common keys). And example of the section may look something like this: db_connections: default: url: 'dialect+driver:////absolute/path/to/database1.db' custom_db_conn_key: url: 'dialect+driver:///./relative/path/to/database2.db' Between this section and connections.py, the key \"default\" must be specified if any connection key is specified (it is possible to not specify any connection keys for certain use cases without database views in SQL). If a username and password is required in the URL, then they can be set using squirrels set-credential <key> with some credential key (see the [Credential Management CLI guide]). Then, you can specify the credential key under the connection key with the attribute credential_key and use the placeholders ${username} and ${password} in the URL. If credential_key is null or not set, the ${username} and ${password} placeholders will become empty strings. See example below for specifying a connection key with credentials. db_connections: default: credential_key: some_key url: 'dialect+driver://${username}:${password}@//path/to/database1.db' For details on using a connections.py file, see the Configure Database Connections how-to guide.","title":"db_connections"},{"location":"topics/manifest/#datasets","text":"In this section, the list of dataset names and dataset attributes can be defined. Under each dataset name, the attributes are the label , database_views , final_view , and args . Any dataset name specified here must also have the same folder name in the datasets folder. The label is simply the display name for the dataset to appear as in a dropdown menu. This attribute is required. The database_views specifies the list of database view names and database view attributes can be defined. This attribute can be optional if no database views are required. Under the database view name, the required attribute is file , and optional attributes are db_connection and args . Or for simplicity, the value mapped to the database view name can also be a string for the equivalent file attribute. - The file must be a Jinja SQL or Python file relative to the dataset folder. - The db_connection is the database connection defined in the db_connections section or connections.py. If db_connection is not specified, it defaults to \"default\". - The args is for specifying arguments at the database view level, and can override arguments specified at the project level or dataset level. These arguments can be referenced by any database view or final view file. The final_view represents the final query for the dataset. It can be a Jinja SQL or Python file relative to the dataset folder (which can reference the results of the database views), or it can be the name of a database view. This attribute is required. The args attribute is for specifying arguments at the dataset level, and can override arguments specified at the project level (i.e., the project variables). This attribute is optional. Below shows an example of using the datasets section to construct a single sample dataset with 2 database views. datasets: sample_dataset: label: Sample Dataset database_views: database_view1: file: db_view1.sql.j2 db_connection: custom_db_conn_key args: arg1: db_view_val1 arg2: db_view_val2 database_view2: db_view2.py final_view: final_view.sql.j2 args: arg0: dataset_val0 arg1: dataset_val1","title":"datasets"},{"location":"topics/manifest/#settings","text":"Certain settings can be specified in this setting. This section is optional if no settings need to be changed from their defaults. Below is an example of using this section. settings: parameters.cache.size: 1024 parameters.cache.ttl: 86400 Here are the current list of setting keys available. Deafult is used when the key is not specified. Setting Key Default Description parameters.cache.size 1024 The maximum number of responses that the LRU cache of the parameters API can store parameters.cache.ttl 86400 The time to live (in seconds) for the LRU cache of the parameters API. Default is 1 day results.cache.size 128 The maximum number of responses that the LRU cache of the results API can store results.cache.ttl 3600 The time to live (in seconds) for the LRU cache of the results API. Default is 1 hour","title":"settings"},{"location":"topics/versioning/","text":"Major vs Minor Version (Best Practices) The general guideline is to increment major version if introducing a breaking change for the REST API consumer, and increment minor version when all changes are non-breaking changes. We can assume the API consumer are following the guidelines specified here . Below are some examples of when to increment each. Increment Major Version When: Deleting or renaming a dataset Deleting or renaming column names Deleting or renaming parameter names Deleting a selection parameter option id (renaming an id should be prohibited) Changing the bounds for a number parameter Increment Minor Version When: Adding a dataset Adding column names Adding parameters Adding selection parameter options Setting an existing dataset as deprecated (capability TBA) Setting an existing column name as deprecated (capability TBA) Setting an existing parameter as deprecated (capability TBA) Setting an existing selection parameter option as deprecated (capability TBA)","title":"Major vs Minor Version (Best Practices)"},{"location":"topics/versioning/#major-vs-minor-version-best-practices","text":"The general guideline is to increment major version if introducing a breaking change for the REST API consumer, and increment minor version when all changes are non-breaking changes. We can assume the API consumer are following the guidelines specified here . Below are some examples of when to increment each. Increment Major Version When: Deleting or renaming a dataset Deleting or renaming column names Deleting or renaming parameter names Deleting a selection parameter option id (renaming an id should be prohibited) Changing the bounds for a number parameter Increment Minor Version When: Adding a dataset Adding column names Adding parameters Adding selection parameter options Setting an existing dataset as deprecated (capability TBA) Setting an existing column name as deprecated (capability TBA) Setting an existing parameter as deprecated (capability TBA) Setting an existing selection parameter option as deprecated (capability TBA)","title":"Major vs Minor Version (Best Practices)"},{"location":"tutorial/conclusion/","text":"What's Next? A Squirrels project may also contain multiple datasets, or datasets with multiple database views, but that's outside the scope of this tutorial. For an expanded version of the \"seattle weather example\" project, see this git repo here: https://github.com/squirrels-nest/weather-analytics-api-example It serves as an example of how to share common Python code or SQL across multiple datasets while allowing their parameter or query definitions to differ. You can also see this page for how to \" Design for Commonality and Variability \". In addition, see the topic guide for Versioning Best Practices for understanding when to increment the major and minor version for your squirrels project. If you're working with dates, check out this guide for how to Modify Dates Using Squirrels . A user guide for the available classes/methods in squirrels library is not yet available, but hopefully, navigating them in an IDE shouldn't be too difficult as docstrings are provided for all public methods. Given this, you should be all ready to create your own project!","title":"What's Next?"},{"location":"tutorial/conclusion/#whats-next","text":"A Squirrels project may also contain multiple datasets, or datasets with multiple database views, but that's outside the scope of this tutorial. For an expanded version of the \"seattle weather example\" project, see this git repo here: https://github.com/squirrels-nest/weather-analytics-api-example It serves as an example of how to share common Python code or SQL across multiple datasets while allowing their parameter or query definitions to differ. You can also see this page for how to \" Design for Commonality and Variability \". In addition, see the topic guide for Versioning Best Practices for understanding when to increment the major and minor version for your squirrels project. If you're working with dates, check out this guide for how to Modify Dates Using Squirrels . A user guide for the available classes/methods in squirrels library is not yet available, but hopefully, navigating them in an IDE shouldn't be too difficult as docstrings are provided for all public methods. Given this, you should be all ready to create your own project!","title":"What's Next?"},{"location":"tutorial/context/","text":"Use the Context File Let's revisit the SQL/Jinja files. In both files, we use prms[\"group_by\"].get_selected(\"dim_col\") to get the dim_col attribute from the selected parameter option. Doing all this in a SQL/Jinja file can be a poor developer experience, especially if you're using an IDE that can provide auto-completion for Python files. Instead, we can use the context.py file to improve the developer experience. We use its main function to transform all selected parameter options into useful values (usually strings) returned as dictionary values. Then, in the SQL/Jinja files, the dictionary can be referenced using the ctx keyword. For example, we can update the context.py file contents to look like this: from typing import Dict, Any import squirrels as sr def main(prms: Dict[str, sr.Parameter], args: Dict[str, Any], *p_args, **kwargs) -> Dict[str, Any]: group_by_param: sr.SingleSelectParameter = prms[\"group_by\"] return { \"dim_col\": group_by_param.get_selected(\"dim_col\"), \"order_col\": group_by_param.get_selected(\"order_by_col\", default_field=\"dim_col\") } Notice that type hints were added to group_by_param . This is useful to provide the IDE information on suggesting methods to auto-complete. For instance, with a list of suggestions, we don't have to memorize that the .get_selected() method exists for SingleSelectParameter objects to get the selected parameter option, or memorize what the method names are available for other parameter classes. Auto-completion would allow these methods to be discovered more easily. At this point, the SQL queries can be written more concisely to reference the context variables instead. The contents for aggr_weather_metrics.sql.j2 can be changed to the following. SELECT {{ ctx[\"dim_col\"] }} , {{ ctx[\"order_col\"] }} as ordering , avg(temp_max) as temperature_high_C , avg(temp_min) as temperature_low_C , avg(precipitation) as precipitation_inches , avg(wind) as wind_mph FROM weather GROUP BY {{ ctx[\"dim_col\"] }}, {{ ctx[\"order_col\"] }} In addition, the contents for final_view.sql.j2 can now be changed to the following. SELECT {{ ctx[\"dim_col\"] }} , temperature_high_C , temperature_low_C , precipitation_inches , wind_mph FROM aggregate_weather_metrics ORDER BY ordering Congratulations, you have reached the end of the tutorial!","title":"6. Use the Context File"},{"location":"tutorial/context/#use-the-context-file","text":"Let's revisit the SQL/Jinja files. In both files, we use prms[\"group_by\"].get_selected(\"dim_col\") to get the dim_col attribute from the selected parameter option. Doing all this in a SQL/Jinja file can be a poor developer experience, especially if you're using an IDE that can provide auto-completion for Python files. Instead, we can use the context.py file to improve the developer experience. We use its main function to transform all selected parameter options into useful values (usually strings) returned as dictionary values. Then, in the SQL/Jinja files, the dictionary can be referenced using the ctx keyword. For example, we can update the context.py file contents to look like this: from typing import Dict, Any import squirrels as sr def main(prms: Dict[str, sr.Parameter], args: Dict[str, Any], *p_args, **kwargs) -> Dict[str, Any]: group_by_param: sr.SingleSelectParameter = prms[\"group_by\"] return { \"dim_col\": group_by_param.get_selected(\"dim_col\"), \"order_col\": group_by_param.get_selected(\"order_by_col\", default_field=\"dim_col\") } Notice that type hints were added to group_by_param . This is useful to provide the IDE information on suggesting methods to auto-complete. For instance, with a list of suggestions, we don't have to memorize that the .get_selected() method exists for SingleSelectParameter objects to get the selected parameter option, or memorize what the method names are available for other parameter classes. Auto-completion would allow these methods to be discovered more easily. At this point, the SQL queries can be written more concisely to reference the context variables instead. The contents for aggr_weather_metrics.sql.j2 can be changed to the following. SELECT {{ ctx[\"dim_col\"] }} , {{ ctx[\"order_col\"] }} as ordering , avg(temp_max) as temperature_high_C , avg(temp_min) as temperature_low_C , avg(precipitation) as precipitation_inches , avg(wind) as wind_mph FROM weather GROUP BY {{ ctx[\"dim_col\"] }}, {{ ctx[\"order_col\"] }} In addition, the contents for final_view.sql.j2 can now be changed to the following. SELECT {{ ctx[\"dim_col\"] }} , temperature_high_C , temperature_low_C , precipitation_inches , wind_mph FROM aggregate_weather_metrics ORDER BY ordering Congratulations, you have reached the end of the tutorial!","title":"Use the Context File"},{"location":"tutorial/initialize/","text":"Initialize a Squirrels Project You can initialize the project files using: squirrels init Prompts will appear for the various files you wish to include in your project. Answer the prompts as follows: [?] Include all core project files? (Y/n): y [?] What's the file format for the database view?: sql > sql py [?] Do you want to add a 'connections.py' file? (y/N): n [?] Do you want to add a 'context.py' file? (y/N): n [?] Do you want to add a 'selections.cfg' file? (y/N): n [?] What's the file format for the final view (if any)?: none > none sql py [?] What sample sqlite database do you wish to use (if any)?: sample_database none > sample_database seattle_weather Once the command is executed, the following files are created. .gitignore , requirements.txt , and squirrels.yaml at the project root parameters.py and database_view.sql.j2 in the datasets/sample_dataset subfolder sample_database.db sqlite database in the database folder If we exclude the sqlite database and files that are common for all Python git projects, then squirrels.yaml , parameters.py , and database_view.sql.j2 are essentially all you need to have a working squirrels project! Go ahead and take a quick glance at the new files (no need to fully understand them now). Then, run the API server using the command: squirrels run In a web browser, go to http://localhost:8000/ or http://127.0.0.1:8000/ . This leads you to the Squirrels UI, a convenient interface for testing the dataset APIs. Without changing the widget parameters, click the \"Apply\" button to display the dataset for the default parameter selections (take some time now to generate various datasets using different parameter selections). To see the API endpoints that provides the information on the parameters and tabular results on the \"Sample Dataset\", you can use the following URLs to access the JSON results for the default parameter selections: Parameters API: http://localhost:8000/squirrels0/sample/v1/sample-dataset/parameters Dataset API: http://localhost:8000/squirrels0/sample/v1/sample-dataset After you're done with the API server, you can terminate it in the terminal by pressing \"Ctrl+C\". Now, we will use the init command again to add more files that'll come in handy for the rest of the tutorial. Run: squirrels init --context --selections-cfg --final-view sql --sample-db seattle_weather The following files have been added. context.py , final_view.sql.j2 , and selections.cfg in the datasets/sample_dataset subfolder seattle_weather.db sqlite database in the database folder Note that when specifying arguments to the squirrels init command, prompts no longer show up. You can see squirrels init --help for more details on what various command line arguments do. Currently, all arguments except \"--help\" and \"--overwrite\" disables the prompts. See the next tutorial page to Configure the Manifest File .","title":"1. Initialize a Squirrels Project"},{"location":"tutorial/initialize/#initialize-a-squirrels-project","text":"You can initialize the project files using: squirrels init Prompts will appear for the various files you wish to include in your project. Answer the prompts as follows: [?] Include all core project files? (Y/n): y [?] What's the file format for the database view?: sql > sql py [?] Do you want to add a 'connections.py' file? (y/N): n [?] Do you want to add a 'context.py' file? (y/N): n [?] Do you want to add a 'selections.cfg' file? (y/N): n [?] What's the file format for the final view (if any)?: none > none sql py [?] What sample sqlite database do you wish to use (if any)?: sample_database none > sample_database seattle_weather Once the command is executed, the following files are created. .gitignore , requirements.txt , and squirrels.yaml at the project root parameters.py and database_view.sql.j2 in the datasets/sample_dataset subfolder sample_database.db sqlite database in the database folder If we exclude the sqlite database and files that are common for all Python git projects, then squirrels.yaml , parameters.py , and database_view.sql.j2 are essentially all you need to have a working squirrels project! Go ahead and take a quick glance at the new files (no need to fully understand them now). Then, run the API server using the command: squirrels run In a web browser, go to http://localhost:8000/ or http://127.0.0.1:8000/ . This leads you to the Squirrels UI, a convenient interface for testing the dataset APIs. Without changing the widget parameters, click the \"Apply\" button to display the dataset for the default parameter selections (take some time now to generate various datasets using different parameter selections). To see the API endpoints that provides the information on the parameters and tabular results on the \"Sample Dataset\", you can use the following URLs to access the JSON results for the default parameter selections: Parameters API: http://localhost:8000/squirrels0/sample/v1/sample-dataset/parameters Dataset API: http://localhost:8000/squirrels0/sample/v1/sample-dataset After you're done with the API server, you can terminate it in the terminal by pressing \"Ctrl+C\". Now, we will use the init command again to add more files that'll come in handy for the rest of the tutorial. Run: squirrels init --context --selections-cfg --final-view sql --sample-db seattle_weather The following files have been added. context.py , final_view.sql.j2 , and selections.cfg in the datasets/sample_dataset subfolder seattle_weather.db sqlite database in the database folder Note that when specifying arguments to the squirrels init command, prompts no longer show up. You can see squirrels init --help for more details on what various command line arguments do. Currently, all arguments except \"--help\" and \"--overwrite\" disables the prompts. See the next tutorial page to Configure the Manifest File .","title":"Initialize a Squirrels Project"},{"location":"tutorial/installation/","text":"Installation First, create and activate a virtual environment for your squirrels project (see python virtual environments for reference). To install the squirrels library in your virtual environment, simply run: pip install squirrels","title":"Installation"},{"location":"tutorial/installation/#installation","text":"First, create and activate a virtual environment for your squirrels project (see python virtual environments for reference). To install the squirrels library in your virtual environment, simply run: pip install squirrels","title":"Installation"},{"location":"tutorial/manifest/","text":"Configure the Manifest File Go to the squirrels.yaml file. This is the manifest file to configure most of the properties of the Squirrels project. In this tutorial, we will focus on the project_variables , db_connections , and datasets sections. Setting the Project Variables The project variables product , major_version , and minor_version are required. In additional to those, you are free to add any of your own project variable. In this tutorial, we will be making dataset APIs related to historical weather data in Seattle. Change the product to seattle_weather . We can leave major_version and minor_version unchanged. The project_variables section should now look like this: project_variables: product: seattle_weather major_version: 1 minor_version: 0 Setting the Database Connections This section is where we set all the database connection details that we need. We provide a list of connection names here and refer to them in other files. The connection name default must be provided for components with sql queries that don't specify a connection name explicitly. Under default , change the url from sqlite://${username}:${password}@/./database/sample_database.db to sqlite:///./database/seattle_weather.db . The syntax for the URL uses sqlalchemy database URLs . Since sqlite databases don't require a username and password, the credential_key field can be either set to null or omitted entirely. More details on setting and using credential keys can be found in the pages for \" credential management \" command line reference and how to \" Configure Database Connections \". The db_connections section should now look like this: db_connections: default: url: 'sqlite:///./database/seattle_weather.db' Note The db_connections section is optional if you choose to set the connection details in Python with a connections.py file or if your squirrels project doesn't require any database connections. More details can be found on the \" Configure Database Connections \" page. Defining the Datasets This section is where we define the attributes for all datasets created by the squirrels project. Every dataset defined will have their own \"parameters API\" and \"dataset API\". Currently, there is one dataset with the name sample_dataset (and label Sample Dataset ). Change the name to weather_by_time , and change the label to Weather by Time of Year . Every dataset defined would have 0 or more database_views and exactly 1 final_view . Each of the database_views and final_view can either be: A string for the file name of the SQL file (templated with Jinja ) or Python file to run. Or... An object with the file key (for the same file name in item 1 above) and additional optional keys such as db_connection and args . In addition to being a templated SQL or Python file, the final_view can also be a string for the name of one of the database views. For database views, if db_connection is not specified (including if the value is string for file name instead of object), then \"default\" is used for db_connection . Change the name database_view1 to aggregate_weather_metrics , and replace its value from an object to the string aggr_weather_metrics.sql.j2 . Change the value of final_view to final_view.sql.j2 . datasets: weather_by_time: label: Weather by Time of Year database_views: aggregate_weather_metrics: aggr_weather_metrics.sql.j2 final_view: final_view.sql.j2 Every dataset that's set in the datasets section must also have a matching folder name in datasets folder. In the datasets folder, rename sample_dataset to weather_by_time . Inside the folder, rename database_view1.sql.j2 to aggr_weather_metrics.sql.j2 . More details on the manifest file can be found in the Manifest File topic guide. See the next tutorial page to Create the Dataset Parameters .","title":"2. Configure the Manifest File"},{"location":"tutorial/manifest/#configure-the-manifest-file","text":"Go to the squirrels.yaml file. This is the manifest file to configure most of the properties of the Squirrels project. In this tutorial, we will focus on the project_variables , db_connections , and datasets sections.","title":"Configure the Manifest File"},{"location":"tutorial/manifest/#setting-the-project-variables","text":"The project variables product , major_version , and minor_version are required. In additional to those, you are free to add any of your own project variable. In this tutorial, we will be making dataset APIs related to historical weather data in Seattle. Change the product to seattle_weather . We can leave major_version and minor_version unchanged. The project_variables section should now look like this: project_variables: product: seattle_weather major_version: 1 minor_version: 0","title":"Setting the Project Variables"},{"location":"tutorial/manifest/#setting-the-database-connections","text":"This section is where we set all the database connection details that we need. We provide a list of connection names here and refer to them in other files. The connection name default must be provided for components with sql queries that don't specify a connection name explicitly. Under default , change the url from sqlite://${username}:${password}@/./database/sample_database.db to sqlite:///./database/seattle_weather.db . The syntax for the URL uses sqlalchemy database URLs . Since sqlite databases don't require a username and password, the credential_key field can be either set to null or omitted entirely. More details on setting and using credential keys can be found in the pages for \" credential management \" command line reference and how to \" Configure Database Connections \". The db_connections section should now look like this: db_connections: default: url: 'sqlite:///./database/seattle_weather.db' Note The db_connections section is optional if you choose to set the connection details in Python with a connections.py file or if your squirrels project doesn't require any database connections. More details can be found on the \" Configure Database Connections \" page.","title":"Setting the Database Connections"},{"location":"tutorial/manifest/#defining-the-datasets","text":"This section is where we define the attributes for all datasets created by the squirrels project. Every dataset defined will have their own \"parameters API\" and \"dataset API\". Currently, there is one dataset with the name sample_dataset (and label Sample Dataset ). Change the name to weather_by_time , and change the label to Weather by Time of Year . Every dataset defined would have 0 or more database_views and exactly 1 final_view . Each of the database_views and final_view can either be: A string for the file name of the SQL file (templated with Jinja ) or Python file to run. Or... An object with the file key (for the same file name in item 1 above) and additional optional keys such as db_connection and args . In addition to being a templated SQL or Python file, the final_view can also be a string for the name of one of the database views. For database views, if db_connection is not specified (including if the value is string for file name instead of object), then \"default\" is used for db_connection . Change the name database_view1 to aggregate_weather_metrics , and replace its value from an object to the string aggr_weather_metrics.sql.j2 . Change the value of final_view to final_view.sql.j2 . datasets: weather_by_time: label: Weather by Time of Year database_views: aggregate_weather_metrics: aggr_weather_metrics.sql.j2 final_view: final_view.sql.j2 Every dataset that's set in the datasets section must also have a matching folder name in datasets folder. In the datasets folder, rename sample_dataset to weather_by_time . Inside the folder, rename database_view1.sql.j2 to aggr_weather_metrics.sql.j2 . More details on the manifest file can be found in the Manifest File topic guide. See the next tutorial page to Create the Dataset Parameters .","title":"Defining the Datasets"},{"location":"tutorial/parameters/","text":"Create the Dataset Parameters Go into the parameters.py file in the weather_by_time dataset folder. This file contains the definitions of all the widget parameters used in the dataset through a main function. The possible widget parameter classes supported today are SingleSelectParameter , MultiSelectParameter , DateParameter , NumberParameter , and DataSourceParameter . The DataSourceParameter represents a parameter based on a lookup table in a database, and can convert itself into one of the other parameter types. The other parameter types should be self-explanatory. The classes are imported from the squirrels library, and all the widget parameter class constructors take name and label as required arguments. The name is what we use to reference the parameter in the dataset queries (as you'll see later in the tutorial), and it's also the name of the corresponding API query parameter. The label represents the human-readable display name to show on the user interface. Different parameter constructors have different required parameters, and most Python IDEs should be able to provide information on the required vs. optional parameters for each constructor. We will start from scratch, so remove all the existing code in the main function body. We will create one single-select parameter to specify the dimension to group by. Define the Parameter Options We first need to specify the list of parameter options. Inside the main function, specify the list of options as such: group_by_options = [ sr.SelectParameterOption('0', 'Year', dim_col='year'), sr.SelectParameterOption('1', 'Quarter', dim_col='quarter'), sr.SelectParameterOption('2', 'Month', dim_col='month_name', order_by_col='month_order'), sr.SelectParameterOption('3', 'Day of Year', dim_col='day_of_year'), sr.SelectParameterOption('4', 'Condition', dim_col='condition') ] The first two parameters to the SelectParameterOption constructors are the ID and label. The ID that must be distinct across options and would never change in the future. For example, once the API consumers associate ID \"0\" to mean \"group by year\" then that association should never be broken even if the label or the ordering of the dropdown options change. Arbitrary keyword arguments such as dim_col and order_by_col can be specified to the SelectParameterOption constructor which will be treated as custom fields to the parameter option that can be used later. See this page for how to Set Parameter Option Custom Fields . Note The SelectParameterOption class has an is_default attribute to specify the parameter option(s) that are selected by default. By default, is_default is set to False. When none of the parameter options have is_default as True, the first option is default for single-select parameters, and nothing is selected by default for multi-select parameter. Define the Parameters The main function must return a Sequence[Parameter] (where Parameter is a class from the squirrels library). We can define our \"group_by_parameter\" as such: group_by_param = sr.SingleSelectParameter('group_by', 'Group By', group_by_options) Since this is the only parameter we are making for this dataset, we can return the parameter set like this: return [group_by_param] End State The contents of the parameters.py file should now look like this: from typing import Sequence, Dict, Any import squirrels as sr def main(args: Dict[str, Any], *p_args, **kwargs) -> Sequence[sr.Parameter]: group_by_options = [ sr.SelectParameterOption('0', 'Year', dim_col='year'), sr.SelectParameterOption('1', 'Quarter', dim_col='quarter'), sr.SelectParameterOption('2', 'Month', dim_col='month_name', order_by_col='month_order'), sr.SelectParameterOption('3', 'Day of Year', dim_col='day_of_year'), sr.SelectParameterOption('4', 'Condition', dim_col='condition') ] group_by_param = sr.SingleSelectParameter('group_by', 'Group By', group_by_options) return [group_by_param] See the next tutorial page to Create the SQL Queries .","title":"3. Create the Dataset Parameters"},{"location":"tutorial/parameters/#create-the-dataset-parameters","text":"Go into the parameters.py file in the weather_by_time dataset folder. This file contains the definitions of all the widget parameters used in the dataset through a main function. The possible widget parameter classes supported today are SingleSelectParameter , MultiSelectParameter , DateParameter , NumberParameter , and DataSourceParameter . The DataSourceParameter represents a parameter based on a lookup table in a database, and can convert itself into one of the other parameter types. The other parameter types should be self-explanatory. The classes are imported from the squirrels library, and all the widget parameter class constructors take name and label as required arguments. The name is what we use to reference the parameter in the dataset queries (as you'll see later in the tutorial), and it's also the name of the corresponding API query parameter. The label represents the human-readable display name to show on the user interface. Different parameter constructors have different required parameters, and most Python IDEs should be able to provide information on the required vs. optional parameters for each constructor. We will start from scratch, so remove all the existing code in the main function body. We will create one single-select parameter to specify the dimension to group by.","title":"Create the Dataset Parameters"},{"location":"tutorial/parameters/#define-the-parameter-options","text":"We first need to specify the list of parameter options. Inside the main function, specify the list of options as such: group_by_options = [ sr.SelectParameterOption('0', 'Year', dim_col='year'), sr.SelectParameterOption('1', 'Quarter', dim_col='quarter'), sr.SelectParameterOption('2', 'Month', dim_col='month_name', order_by_col='month_order'), sr.SelectParameterOption('3', 'Day of Year', dim_col='day_of_year'), sr.SelectParameterOption('4', 'Condition', dim_col='condition') ] The first two parameters to the SelectParameterOption constructors are the ID and label. The ID that must be distinct across options and would never change in the future. For example, once the API consumers associate ID \"0\" to mean \"group by year\" then that association should never be broken even if the label or the ordering of the dropdown options change. Arbitrary keyword arguments such as dim_col and order_by_col can be specified to the SelectParameterOption constructor which will be treated as custom fields to the parameter option that can be used later. See this page for how to Set Parameter Option Custom Fields . Note The SelectParameterOption class has an is_default attribute to specify the parameter option(s) that are selected by default. By default, is_default is set to False. When none of the parameter options have is_default as True, the first option is default for single-select parameters, and nothing is selected by default for multi-select parameter.","title":"Define the Parameter Options"},{"location":"tutorial/parameters/#define-the-parameters","text":"The main function must return a Sequence[Parameter] (where Parameter is a class from the squirrels library). We can define our \"group_by_parameter\" as such: group_by_param = sr.SingleSelectParameter('group_by', 'Group By', group_by_options) Since this is the only parameter we are making for this dataset, we can return the parameter set like this: return [group_by_param]","title":"Define the Parameters"},{"location":"tutorial/parameters/#end-state","text":"The contents of the parameters.py file should now look like this: from typing import Sequence, Dict, Any import squirrels as sr def main(args: Dict[str, Any], *p_args, **kwargs) -> Sequence[sr.Parameter]: group_by_options = [ sr.SelectParameterOption('0', 'Year', dim_col='year'), sr.SelectParameterOption('1', 'Quarter', dim_col='quarter'), sr.SelectParameterOption('2', 'Month', dim_col='month_name', order_by_col='month_order'), sr.SelectParameterOption('3', 'Day of Year', dim_col='day_of_year'), sr.SelectParameterOption('4', 'Condition', dim_col='condition') ] group_by_param = sr.SingleSelectParameter('group_by', 'Group By', group_by_options) return [group_by_param] See the next tutorial page to Create the SQL Queries .","title":"End State"},{"location":"tutorial/queries/","text":"Create the SQL Queries In the weather_by_time dataset folder, rename database_view1.sql.j2 to aggr_weather_metrics.sql.j2 if you haven't already. The final_view.sql.j2 file name can remain the same. In these files, we will write the analytical sql query to return tabular results for the dataset. These sql query can be templated using Jinja, with access to the prms , ctx , and args variables which stand for \"Parameter Set\", \"Context\", and \"Arguments\" respectively. More information about these variables can be found in the how to \" Create Views with SQL and Jinja \" page. For now, just know that we can access the selected parameter value(s) by using prms[\"parameter name\"] in Jinja. Define the Database View In aggr_weather_metrics.sql.j2 , change its contents to the following: {% set dim_col = prms[\"group_by\"].get_selected(\"dim_col\") -%} {% set order_col = prms[\"group_by\"].get_selected(\"order_by_col\", default_field=\"dim_col\") -%} SELECT {{ dim_col }} , {{ order_col }} as ordering , avg(temp_max) as temperature_high_C , avg(temp_min) as temperature_low_C , avg(precipitation) as precipitation_inches , avg(wind) as wind_mph FROM weather GROUP BY {{ dim_col }}, {{ order_col }} This query finds the average temperature, precipitation level, and wind speed by year, or by year of month, or by day of year, etc. based the selected value of the group_by parameter. The set keyword is Jinja syntax for assigning variables. The prms['group_by'] returns a SingleSelectParameter (as we previously defined in parameters.py ), which contains the method .get_selected() for getting specific fields of the selected SelectParameterOption . We've previously defined dim_col in all the options in parameters.py , but only specified order_by_col for one of the option. The .get_selected() has the argument \"default_field\" to pick dim_col for the order_by_col if order_by_col does not exist as a custom field. Define the Final View In final_view.sql.j2 , change its contents to the following: {% set dim_col = prms[\"group_by\"].get_selected(\"dim_col\") -%} SELECT {{ dim_col }} , temperature_high_C , temperature_low_C , precipitation_inches , wind_mph FROM aggregate_weather_metrics ORDER BY ordering A few things to notice here: The table aggregate_weather_metrics in the \"FROM\" clause is the name of the database view we defined in aggr_weather_metrics.sql.j2 . The name was specified in squirrels.yaml . In this query, we are selecting all columns except the ordering column, which is what we use in the \"ORDER BY\" clause instead. The first line where we set dim_col is repeated with the database view file. This can be avoided either by using Jinja's include/import , or by using a context.py file which will be discussed later in the tutorial. See the next tutorial page to Test the REST APIs .","title":"4. Create the SQL Queries"},{"location":"tutorial/queries/#create-the-sql-queries","text":"In the weather_by_time dataset folder, rename database_view1.sql.j2 to aggr_weather_metrics.sql.j2 if you haven't already. The final_view.sql.j2 file name can remain the same. In these files, we will write the analytical sql query to return tabular results for the dataset. These sql query can be templated using Jinja, with access to the prms , ctx , and args variables which stand for \"Parameter Set\", \"Context\", and \"Arguments\" respectively. More information about these variables can be found in the how to \" Create Views with SQL and Jinja \" page. For now, just know that we can access the selected parameter value(s) by using prms[\"parameter name\"] in Jinja.","title":"Create the SQL Queries"},{"location":"tutorial/queries/#define-the-database-view","text":"In aggr_weather_metrics.sql.j2 , change its contents to the following: {% set dim_col = prms[\"group_by\"].get_selected(\"dim_col\") -%} {% set order_col = prms[\"group_by\"].get_selected(\"order_by_col\", default_field=\"dim_col\") -%} SELECT {{ dim_col }} , {{ order_col }} as ordering , avg(temp_max) as temperature_high_C , avg(temp_min) as temperature_low_C , avg(precipitation) as precipitation_inches , avg(wind) as wind_mph FROM weather GROUP BY {{ dim_col }}, {{ order_col }} This query finds the average temperature, precipitation level, and wind speed by year, or by year of month, or by day of year, etc. based the selected value of the group_by parameter. The set keyword is Jinja syntax for assigning variables. The prms['group_by'] returns a SingleSelectParameter (as we previously defined in parameters.py ), which contains the method .get_selected() for getting specific fields of the selected SelectParameterOption . We've previously defined dim_col in all the options in parameters.py , but only specified order_by_col for one of the option. The .get_selected() has the argument \"default_field\" to pick dim_col for the order_by_col if order_by_col does not exist as a custom field.","title":"Define the Database View"},{"location":"tutorial/queries/#define-the-final-view","text":"In final_view.sql.j2 , change its contents to the following: {% set dim_col = prms[\"group_by\"].get_selected(\"dim_col\") -%} SELECT {{ dim_col }} , temperature_high_C , temperature_low_C , precipitation_inches , wind_mph FROM aggregate_weather_metrics ORDER BY ordering A few things to notice here: The table aggregate_weather_metrics in the \"FROM\" clause is the name of the database view we defined in aggr_weather_metrics.sql.j2 . The name was specified in squirrels.yaml . In this query, we are selecting all columns except the ordering column, which is what we use in the \"ORDER BY\" clause instead. The first line where we set dim_col is repeated with the database view file. This can be avoided either by using Jinja's include/import , or by using a context.py file which will be discussed later in the tutorial. See the next tutorial page to Test the REST APIs .","title":"Define the Final View"},{"location":"tutorial/testapi/","text":"Test the REST APIs In the weather_by_time datasets folder, go into context.py and replace the body of the main function to: return {} We will discuss the context.py file later in the tutorial, but for now, we are clearing it such that we can activate the REST APIs without errors. To activate the API server, simply run: squirrels run --debug Note The --debug argument is optional here. This is specified to be able to test with hidden parameters, though no hidden parameters were set up for this tutorial. See squirrels run --help or the \" run command line \" page for more details. Then, in a web browser, go to http://localhost:8000/ to interact with the dataset APIs you've just created using the Squirrels UI! Remember to shut down the API server by pressing \"Ctrl+C\" before proceeding to the next step. Test the Rendered SQL Queries In practice, you may wish to review what the rendered SQL queries look like (for some set of parameter selections) before actually running the queries. To do this for the weather_by_time dataset (using the default parameter selections), run: squirrels test weather_by_time This creates the folder path outputs/weather_by_time with the generated SQL queries (without actually running them). Take a look at the files in the folder to see what got generated. To run the generated queries as well, and write results as csv files, use the following to command. squirrels test weather_by_time --runquery We can also test on non-default parameter selections. In the dataset folder, change the contents of the selections.cfg file to: [parameters] group_by = 2 When we define multiple parameters, the order of the parameters specified here must be the same as the order as defined in the parameters.py file (especially if cascading parameters exist). The \"2\" is the ID of the \"Month\" option for the group_by parameter. Run the following to render the SQL queries with selections.cfg : squirrels test weather_by_time --cfg selections.cfg See squirrels test --help or the page for the \" test command line \" for more details. See the next tutorial page to Use the Context File .","title":"5. Activate the REST APIs & Test"},{"location":"tutorial/testapi/#test-the-rest-apis","text":"In the weather_by_time datasets folder, go into context.py and replace the body of the main function to: return {} We will discuss the context.py file later in the tutorial, but for now, we are clearing it such that we can activate the REST APIs without errors. To activate the API server, simply run: squirrels run --debug Note The --debug argument is optional here. This is specified to be able to test with hidden parameters, though no hidden parameters were set up for this tutorial. See squirrels run --help or the \" run command line \" page for more details. Then, in a web browser, go to http://localhost:8000/ to interact with the dataset APIs you've just created using the Squirrels UI! Remember to shut down the API server by pressing \"Ctrl+C\" before proceeding to the next step.","title":"Test the REST APIs"},{"location":"tutorial/testapi/#test-the-rendered-sql-queries","text":"In practice, you may wish to review what the rendered SQL queries look like (for some set of parameter selections) before actually running the queries. To do this for the weather_by_time dataset (using the default parameter selections), run: squirrels test weather_by_time This creates the folder path outputs/weather_by_time with the generated SQL queries (without actually running them). Take a look at the files in the folder to see what got generated. To run the generated queries as well, and write results as csv files, use the following to command. squirrels test weather_by_time --runquery We can also test on non-default parameter selections. In the dataset folder, change the contents of the selections.cfg file to: [parameters] group_by = 2 When we define multiple parameters, the order of the parameters specified here must be the same as the order as defined in the parameters.py file (especially if cascading parameters exist). The \"2\" is the ID of the \"Month\" option for the group_by parameter. Run the following to render the SQL queries with selections.cfg : squirrels test weather_by_time --cfg selections.cfg See squirrels test --help or the page for the \" test command line \" for more details. See the next tutorial page to Use the Context File .","title":"Test the Rendered SQL Queries"}]}